<div class="container">

<table style="width: 100%;"><tr>
<td>lqmControl</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Control parameters for lqm estimation
</h2>

<h3>Description</h3>

<p>A list of parameters for controlling the fitting process.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lqmControl(method = "gs1", loop_tol_ll = 1e-5, loop_tol_theta = 1e-3,
	check_theta = FALSE, loop_step = NULL, beta = 0.5, gamma = 1.25,
	reset_step = FALSE, loop_max_iter = 1000, smooth = FALSE,
	omicron = 0.001, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>character vector that specifies which code to use for carrying out the gradient search algorithm: "gs1" (default) based on C code and "gs2" based on R code. Method "gs3" uses a smoothed loss function. See details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loop_tol_ll</code></td>
<td>

<p>tolerance expressed as relative change of the log-likelihood.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loop_tol_theta</code></td>
<td>

<p>tolerance expressed as relative change of the estimates.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check_theta</code></td>
<td>

<p>logical flag. If <code>TRUE</code> the algorithm performs a check on the change in the estimates in addition to the likelihood.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loop_step</code></td>
<td>

<p>step size (default standard deviation of response).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>

<p>decreasing step factor for line search (0,1).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>

<p>nondecreasing step factor for line search (&gt;= 1).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reset_step</code></td>
<td>

<p>logical flag. If <code>TRUE</code> the step size is re-setted to the initial value at each iteration.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loop_max_iter</code></td>
<td>

<p>maximum number of iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smooth</code></td>
<td>

<p>logical flag. If <code>TRUE</code> the standard loss function is replaced with a smooth approximation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omicron</code></td>
<td>

<p>small constant for smoothing the loss function when using <code>smooth = TRUE</code>. See details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>logical flag.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The methods "gs1" and "gs2" implement the same algorithm (Bottai et al, 2015). The former is based on C code, the latter on R code. While the C code is faster, the R code seems to be more efficient in handling large datasets. For method "gs2", it is possible to replace the classical non-differentiable loss function with a smooth version (Chen, 2007).
</p>


<h3>Value</h3>

<p>a list of control parameters.
</p>


<h3>Author(s)</h3>

<p>Marco Geraci</p>


<h3>References</h3>

<p>Bottai M, Orsini N, Geraci M (2015). A Gradient Search Maximization Algorithm for the Asymmetric Laplace Likelihood, Journal of Statistical Computation and Simulation, 85(10), 1919-1925.
</p>
<p>Chen C (2007). A finite smoothing algorithm for quantile regression. Journal of Computational and Graphical Statistics, 16(1), 136-164. 
</p>


<h3>See Also</h3>

<p><code>lqm</code>
</p>


</div>