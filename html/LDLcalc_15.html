<div class="container">

<table style="width: 100%;"><tr>
<td>JSDNormal</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate the Jensen-Shannon divergence (JSD) between a discrete
empirical distribution and the normal distribution.</h2>

<h3>Description</h3>

<p>Calculates the Jensen-Shannon divergence between a discrete
distribution and the corresponding normal distribution with mean and standard
deviation the same as these of the discrete one.
</p>


<h3>Usage</h3>

<pre><code class="language-R">JSDNormal(dfSmpl, param)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dfSmpl</code></td>
<td>
<p>A data frame containing the values of the discrete distribution.
The data frame may contain more that one column with discrete distribution
values. The argument "param" specified next will determine which column
will be used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>param</code></td>
<td>
<p>The name of the column to be used.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The function returns the Jensen-Shannon divergence between the
discrete and corresponding normal distribution. It also returns a data frame
with the empirical probability of the values supplied in the column
as well as the empirical probabilies one of the normal discrete distribution.
distribution.
</p>


<h3>References</h3>

<p>D.M. Endres, J.E. Schindelin, A new metric for probability distributions, IEEE
Trans. Inf. Theory (2003), https://doi.org/10.1109/TIT.2003.813506.
</p>
<p>F. Oesterreicher, I. Vajda, A new class of metric divergences on probability spaces
and its applicability in statistics, Ann. Inst. Stat. Math. (2003), https://doi.org/
10.1007/BF02517812.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
JSD.between.empirical.Normal =JSDNormal(sampleA,"LDL")

## End(Not run)
</code></pre>


</div>