<div class="container">

<table style="width: 100%;"><tr>
<td>compare</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model comparison (deprecated, old version)</h2>

<h3>Description</h3>

<p><strong>This function is deprecated</strong>. Please use the new <code>loo_compare()</code> function
instead.
</p>


<h3>Usage</h3>

<pre><code class="language-R">compare(..., x = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>At least two objects returned by <code>loo()</code> (or <code>waic()</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A list of at least two objects returned by <code>loo()</code> (or
<code>waic()</code>). This argument can be used as an alternative to
specifying the objects in <code>...</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>When comparing two fitted models, we can estimate the difference in their
expected predictive accuracy by the difference in <code>elpd_loo</code> or
<code>elpd_waic</code> (or multiplied by -2, if desired, to be on the
deviance scale).
</p>
<p><em>When that difference, <code>elpd_diff</code>, is positive then the expected
predictive accuracy for the second model is higher. A negative
<code>elpd_diff</code> favors the first model.</em>
</p>
<p>When using <code>compare()</code> with more than two models, the values in the
<code>elpd_diff</code> and <code>se_diff</code> columns of the returned matrix are
computed by making pairwise comparisons between each model and the model
with the best ELPD (i.e., the model in the first row).
Although the <code>elpd_diff</code> column is equal to the difference in
<code>elpd_loo</code>, do not expect the <code>se_diff</code> column to be equal to the
the difference in <code>se_elpd_loo</code>.
</p>
<p>To compute the standard error of the difference in ELPD we use a
paired estimate to take advantage of the fact that the same set of <em>N</em>
data points was used to fit both models. These calculations should be most
useful when <em>N</em> is large, because then non-normality of the
distribution is not such an issue when estimating the uncertainty in these
sums. These standard errors, for all their flaws, should give a better
sense of uncertainty than what is obtained using the current standard
approach of comparing differences of deviances to a Chi-squared
distribution, a practice derived for Gaussian linear models or
asymptotically, and which only applies to nested models in any case.
</p>


<h3>Value</h3>

<p>A vector or matrix with class <code>'compare.loo'</code> that has its own
print method. If exactly two objects are provided in <code>...</code> or
<code>x</code>, then the difference in expected predictive accuracy and the
standard error of the difference are returned. If more than two objects are
provided then a matrix of summary information is returned (see <strong>Details</strong>).
</p>


<h3>References</h3>

<p>Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC.
<em>Statistics and Computing</em>. 27(5), 1413â€“1432. doi:10.1007/s11222-016-9696-4
(<a href="https://link.springer.com/article/10.1007/s11222-016-9696-4">journal version</a>,
<a href="https://arxiv.org/abs/1507.04544">preprint arXiv:1507.04544</a>).
</p>
<p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2024).
Pareto smoothed importance sampling. <em>Journal of Machine Learning Research</em>,
25(72):1-58.
<a href="https://jmlr.org/papers/v25/19-556.html">PDF</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
loo1 &lt;- loo(log_lik1)
loo2 &lt;- loo(log_lik2)
print(compare(loo1, loo2), digits = 3)
print(compare(x = list(loo1, loo2)))

waic1 &lt;- waic(log_lik1)
waic2 &lt;- waic(log_lik2)
compare(waic1, waic2)

## End(Not run)

</code></pre>


</div>