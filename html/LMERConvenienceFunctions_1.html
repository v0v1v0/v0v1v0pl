<div class="container">

<table style="width: 100%;"><tr>
<td>LMERConvenienceFunctions-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model Selection and Post-Hoc Analysis for (G)LMER Models</h2>

<h3>Description</h3>

<p>The main function of the package is to perform backward selection of fixed effects, forward fitting of the random effects, and post-hoc analyses using parallel capabilities. Other functionality includes the computation of ANOVAs with upper- or lower-bound p-values and R-squared values for each model term, model criticism plots, data trimming on model residuals, and data visualization. The data to run examples is contained in package <code>LCF_data</code>.</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> LMERConvenienceFunctions</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 3.0</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2020-09-27</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
<td style="text-align: left;">
LazyLoad: </td>
<td style="text-align: left;"> yes</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Antoine Tremblay, Statistics Canada, and Johannes Ransijn, University of Copenhagen
</p>
<p>Maintainer: "Antoine Tremblay, Statistics Canada" &lt;trea26@gmail.com&gt;
</p>


<h3>References</h3>

<p>Baayen, R.H. (2008). <em>Analyzing Linguistic Data. A Practical Introduction to Statistics Using R</em>. Cambridge, UK: Cambridge University Press. 
</p>
<p>Baayen, R.H., Davidson, D.J. and Bates, D.M. (2008). Mixed-effects modeling with crossed random effects for subjects and items. <em>Journal of Memory and Language</em>, <em>59</em>, 390–412.
</p>
<p>Newman, A.J., Tremblay, A., Nichols, E.S., Neville, H.J., and Ullman, M.T. (2012). The Influence of Language Proficiency on Lexical Semantic Processing in Native and Late Learners of English. <em>Journal of Cognitive Neuroscience</em>, <em>25</em>, 1205–1223.
</p>
<p>Newman, A.J., Tremblay, A., Neville, H.J., and Ullman, M.T. (In preparation).  The relationship between proficiency and ERP components evoked by grammatical violations in native and late learners of English.
</p>
<p>Pinheiro, J.C. and Bates, D.M. (2000). <em>Mixed Effects Models in S and S-Plus</em>. New York: Springer.
</p>
<p>Quene, H., &amp; van den Bergh, H. (2008). Examples of mixed-effects modeling with crossed random effects and with binomial data. <em>Journal of Memory and Language</em>, 59, 413–425. doi: 10.1016/j.jml.2008.02.002.
</p>
<p>Symonds, M.R.E and Moussalli, A. (2011). <em>A brief guide to model selection, multimodel inference and model averaging in behavioural ecology using Akaike's information criterion.</em> <em>Behavioral Ecology and Sociobiology</em>, 65, 13–21. doi: 10.1007/s00265-010-1037-6
</p>
<p>Tremblay, Antoine. (2009). <em>Processing Advantages of Lexical Bundles: Evidence from Self-paced Reading, Word and Sentence Recall, and Free Recall with Event-related Brain Potential Recordings</em>. Ph.D. Dissertation. University of Alberta, Edmonton, Canada.
</p>
<p>Tremblay, A. and Tucker B. V. (2011). The Effects of N-gram Probabilistic Measures on the Processing and Production of Four-word Sequences. <em>The Mental Lexicon</em>, <em>6(2)</em>, 302–324.
</p>


<h3>See Also</h3>

<p><code>bfFixefLMER_F.fnc</code>;
<code>bfFixefLMER_t.fnc</code>;
<code>ffRanefLMER.fnc</code>;
<code>fitLMER.fnc</code>;
<code>mcposthoc.fnc</code>;
<code>summary.mcposthoc</code>;
<code>pamer.fnc</code>;
<code>mcp.fnc</code>;
<code>relLik</code>;
<code>romr.fnc</code>;
<code>plotLMER.fnc</code>;
<code>plotLMER3d.fnc</code>;
<code>plotDensity3d.fnc</code>;
<code>plotRaw3d.fnc</code>;
<code>perSubjectTrim.fnc</code>;
<code>cn</code>;
<code>f</code>;
<code>cd</code>;
<code>cdf</code>;
<code>cdup</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
  ############################################
  #            Load and format data.         #
  ############################################
  library(LCFdata)
  data(eeg)

  # restrict to electrode Fz and 80--180 ms window
  eeg &lt;- eeg[eeg$Time &gt;= 80 &amp; eeg$Time &lt;= 180, ]
  eeg &lt;- eeg[, c("Subject", "Item", "Time", "Fz",
    "FreqB", "LengthB", "WMC")]

  # mean center FreqB
  eeg$FreqBc &lt;- eeg$FreqB - mean(eeg$FreqB)
  # split FreqBc into 3 categories. Doesn't make sense, 
  # but it's merely for example
  eeg$FreqBdc &lt;- "high"
  eeg$FreqBdc[eeg$FreqBc&lt;=quantile(eeg$FreqBc)[3]] &lt;- "mid"
  eeg$FreqBdc[eeg$FreqBc&lt;=quantile(eeg$FreqBc)[2]] &lt;- "low"
  eeg$FreqBdc &lt;- as.factor(eeg$FreqBdc)
  eeg$FreqBdc &lt;- relevel(eeg$FreqBdc, "low")

  # mean center LengthB
  eeg$LengthBc &lt;- eeg$LengthB - mean(eeg$LengthB)

  # mean center WMC
  eeg$WMCc &lt;- eeg$WMC - mean(eeg$WMC)

  ############################################
  #      Demonstrate plotDensity3d.fnc.      #
  ############################################
  plotDensity3d.fnc(x = sort(unique(eeg$WMCc)), 
    y = sort(unique(eeg$LengthBc)))

  ############################################
  #        Demonstrate plotRaw3d.fnc.        #
  ############################################
  plotRaw3d.fnc(data = eeg, response = "Fz", pred = "WMCc",
    intr = "LengthBc", plot.type = "persp", theta = 150)

  ############################################
  #       Analyze data. Demonstrate model    #
  #       selection, and diagnostic plots.   #
  #       Also demonstrate forward fitting   #
  #       of random effects and back fitting #
  #       of fixed effects. Finally,         #
  #       demonstrate pamer.fnc.             # 
  ############################################
  library(lme4)
  # fit initial model
  m0 &lt;- lmer(Fz ~ (FreqBdc + LengthBc + WMCc)^2 + (1 | Subject), 
    data = eeg)
  m1 &lt;- lmer(Fz ~ (FreqBdc + LengthBc + WMCc)^2 + (1 | Subject) +
    (1 | Item), data = eeg)

  # which model to choose?
  relLik(m0, m1)

  # choose m1
  # check model assumptions 
  mcp.fnc(m1)

  # remove outliers
  eeg &lt;- romr.fnc(m1, eeg, trim = 2.5)
  eeg$n.removed
  eeg$percent.removed
  eeg&lt;-eeg$data

  # update model
  m1 &lt;- lmer(Fz ~ (FreqBdc + LengthBc + WMCc)^2 + (1 | Subject) +
    (1 | Item), data = eeg)
  
  # re-check model assumptions 
  mcp.fnc(m1)

  # forward-fit random effect structure (simple for the purposes
  # of the example).
  m2 &lt;- ffRanefLMER.fnc(model = m1, ran.effects = 
    c("(0 + LengthBc | Subject)", "(0 + WMCc | Item)"), 
    log.file = FALSE)

  # backfit model m2. In this case, could use bfFixefLMER_t.fnc instead.
  m3 &lt;- bfFixefLMER_F.fnc(m2, log.file = FALSE)

  # The calls to ffRanefLMER.fnc and bfFixefLMER_F.fnc could 
  # be replaced by a call to fitLMER.fnc. In this latter case, however, 
  # bfFixefLMER_F.fnc would be called first, then the random effect 
  # structure would be forward fitted, and finally teh fixed effects
  # would be backfitted again.
  m3b &lt;- fitLMER.fnc(model = m1, ran.effects = c("(0 + LengthBc | Subject)",
    "(0 + WMCc | Item)"), backfit.on = "F", log.file = FALSE)
  pamer.fnc(m3b)
  # The results are the same. This may not necessarily be the case
  # elsewhere. First forward fitting the random effect structure and
  # then backfitting the fixed effects, potentially pruning irrelevant 
  # random effects, is probably the best approach. Nonetheless, there is 
  # no hard evidence to this effect.

  # check model assumptions 
  mcp.fnc(m3)

  # check significance of model terms
  pamer.fnc(m3)

  ############################################
  #       Demonstrate mcposthoc.fnc and      #
  #       summary.mcposthoc.                 #
  ############################################
  # Only the intercept is significant. For purposes of the 
  # example, let's perform a posthoc analysis on FreqBdc on
  # model m2.
  m2.ph &lt;- mcposthoc.fnc(model = m2, var = list(ph1 = "FreqBdc"))

  # Now check if and how the different levels differ between
  # each other. First check high vs mid and high vs low:
  summary(m2.ph, term = "FreqBdchigh") 
  # Then low vs mid (the low vs high row is redundant from the 
  # above summary):
  summary(m2.ph, term = "FreqBdcmid")
  # Note that none of the levels differ from each other. Indeed, 
  # the backfitting process indicated that the model only has an 
  # intercept (i.e., the FreqBc factor variable was not significant).

  # Just to show how one would look at posthocs for interactions. Let's 
  # look at the effect of Length at each FreqB bin:
  summary(object = m2.ph, term = "LengthBc")
  # Does Length effect different Freq bins? Start with low 
  # versus mid and high
  smry &lt;- summary(object = m2.ph, term = "FreqBdchigh:LengthBc")
  # then mid versus low and high
  smry &lt;- summary(object = m2.ph, term = "FreqBdcmid:LengthBc")

  ############################################
  #       Demonstrate `revived' version of   #
  #       plotLMER.fnc and plotLMER3d.fnc.   #
  ############################################
  # Generate plot for Length X Freq with function plotLMER.fnc.
  plotLMER.fnc(m2, pred = "LengthBc", intr = list("FreqBdc", 
    levels(eeg$FreqBdc), "beg", list(1 : 3, 1 : 3)))

  # Plotting the Length:WMC interaction with plotLMER3d.fnc. It'll
  # take a little bit of time.
  plotLMER3d.fnc(m2,"LengthBc","WMCc")
  # Plot it a second time to demonstrate caching. You can notice the 
  # speed-up.
  plotLMER3d.fnc(m2,"LengthBc","WMCc")


  ############################################
  #       Demonstrate modeling and           #
  #       backfitting of glmer.              #
  ############################################
  # Split FreqBc into 2 categories.
  eeg$FreqBdc &lt;- "high"
  eeg$FreqBdc[eeg$FreqBc&lt;=median(eeg$FreqBc)] &lt;- "low"
  eeg$FreqBdc &lt;- as.factor(eeg$FreqBdc)
  eeg$FreqBdc &lt;- relevel(eeg$FreqBdc, "low")

  # Fit glmer model.
  m4 &lt;- glmer(FreqBdc ~ (Fz + LengthBc + WMCc)^2 + (1 | Subject),
	family = "binomial", data = eeg)
  summary(m4)
  pamer.fnc(m4)

  # Back fit fixed effects, forward fit random effects, and then
  # re-back fit fixed effects. Need to set argument backfit.on to "t".
  m5 &lt;- fitLMER.fnc(model = m4, ran.effects = "(0 + LengthBc | Subject)",
	backfit.on = "t", log.file = FALSE)
  summary(m5)
  pamer.fnc(m5)

  # Plot the 2-way interaction.
  plotLMER.fnc(m5, pred = "Fz", intr = list("LengthBc", 
	quantile(eeg$LengthBc), "med",list(1:5,1:5)))

  # Look at the same plot, but in 3d.
  plotLMER3d.fnc(m5, pred = "Fz", intr = "LengthBc")

  ############################################
  #       Test backfitting on AIC,           #
  #       BIC, llrt, relLik.AIC, and         #
  #       relLik.BIC.                        #
  ############################################
  # AIC
  m.test &lt;- bfFixefLMER_F.fnc(m2, method = "AIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m2, method = "AIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m4, method = "AIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_F.fnc(m4, method = "AIC",
	log.file = FALSE)

  # BIC
  m.test &lt;- bfFixefLMER_F.fnc(m2, method = "BIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m2, method = "BIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m4, method = "BIC",
	log.file = FALSE)

  # llrt
  m.test &lt;- bfFixefLMER_F.fnc(m2, method = "llrt",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m2, method = "llrt",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m4, method = "llrt",
	log.file = FALSE)

  # relLik.AIC
  m.test &lt;- bfFixefLMER_F.fnc(m2, method = "relLik.AIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m2, method = "relLik.AIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m4, method = "relLik.AIC",
	log.file = FALSE)

  # relLik.BIC
  m.test &lt;- bfFixefLMER_F.fnc(m2, method = "relLik.BIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m2, method = "relLik.BIC",
	log.file = FALSE)
  m.test &lt;- bfFixefLMER_t.fnc(m4, method = "relLik.BIC",
	log.file = FALSE)

## End(Not run)
</code></pre>


</div>