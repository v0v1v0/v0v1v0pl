<div class="container">

<table style="width: 100%;"><tr>
<td>Combine</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Combine Demonoid Objects</h2>

<h3>Description</h3>

<p>This function combines objects of class <code>demonoid</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">Combine(x, Data, Thinning=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>This is a list of objects of class <code>demonoid</code>, and this
list may be an object of class <code>demonoid.hpc</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Data</code></td>
<td>
<p>This is the data, and must be identical to the data used
to create the <code>demonoid</code> objects with
<code>LaplacesDemon</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Thinning</code></td>
<td>
<p>This is the amount of thinning to apply to the
posterior samples after appending them together. <code>Thinning</code>
defaults to 1, in which case all samples are retained. For example,
in the case of, say, <code>Thinning=10</code>, then only every 10th sample
would be retained. When combining parallel chains, <code>Thinning</code>
is often left to its default. When combining consecutive updates,
<code>Thinning</code> is usually applied, with the value equal to the
number of objects of class <code>demonoid</code>. For more information on
thinning, see the <code>Thin</code> function.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The purpose of the <code>Combine</code> function is to enable a user to
combine objects of class <code>demonoid</code> for one of three
reasons. First, parallel chains from <code>LaplacesDemon.hpc</code>
may be combined after convergence is assessed with
<code>Gelman.Diagnostic</code>. Second, consecutive updates of single
chains from <code>LaplacesDemon</code> or parallel chains from
<code>LaplacesDemon.hpc</code> may be combined when the computer has
insufficient random-access memory (RAM) for the user to update once 
with enough iterations. Third, consecutive single-chain or
parallel-chain updates may be combined when it seems that the
logarithm of the joint posterior distribution, <code>LP</code>, seems to be
oscillating up and down, which is described in more detail below.
</p>
<p>The most common use regards the combination of parallel chains output
from <code>LaplacesDemon.hpc</code>. Typically, a user with parallel
chains examines them graphically with the
<code>caterpillar.plot</code> and <code>plot</code> (actually,
<code>plot.demonoid</code>) functions, and assesses convergence
with the <code>Gelman.Diagnostic</code> function. Thereafter, the
parallel chain output in the object of class <code>demonoid.hpc</code>
should be combined into a single object of class <code>demonoid</code>,
before doing posterior predictive checks and making inferences. In
this case, the <code>Thinning</code> argument usually is recommended to
remain at its default.
</p>
<p>It is also common with a high-dimensional model (a model with a large
number of parameters) to need more posterior samples than allowed by
the random-access memory (RAM) of the computer. In this case, it is
best to use the <code>LaplacesDemon.RAM</code> function to estimate
the amount of RAM that a given model will require with a given number
of iterations, and then update <code>LaplacesDemon</code> almost as
much as RAM allows, and save the output object of class
<code>demonoid</code>. Then, the user is advised to continue onward with a
consecutive update (after using <code>as.initial.values</code> and
anything else appropriate to prepare for the consecutive
update). Suppose a user desires to update a gigantic model with
thousands of parameters, and with the aid of
<code>LaplacesDemon.RAM</code>, estimates that they can safely update
only 100,000 iterations, and that 150,000 iterations would exceed RAM
and crash the computer. The patient user can update several
consecutive models, each with retaining only 1,000 thinned posterior
samples, and combine them later with the <code>Combine</code> function, by
placing multiple objects into a list, as described below. In this way,
it is possible for a user to update models that otherwise far exceed
computer RAM.
</p>
<p>Less commonly, multiple updates of single-chain objects should be
combined into a single object of class <code>demonoid</code>. This is most
useful in complicated models that are run for large numbers of
iterations, where it may be suspected that stationarity has been
achieved, but that thinning is insufficient, and the samples may be
combined and thinned. If followed, then these suggestions may continue
seemingly to infinity, and the unnormalized logarithm of the joint
posterior density, <code>LP</code>, may seem to oscillate, sometimes
improving and getting higher, and getting lower during other updates.
For this purpose, the prior covariance matrix of the last model is
retained (rather than combining them). This may be an unpleasant
surprise for combining parallel updates, so be aware of it.
</p>
<p>In these cases, which usually involve complicated models with high
autocorrelation in the chains, the user may opt to use parallel
processing with the <code>LaplacesDemon.hpc</code> function, or may
use the <code>LaplacesDemon</code> function as follows. The user
should save (meaning, not overwrite) each object of class
<code>demonoid</code>, place multiple objects into a list, and use the
<code>Combine</code> function to combine these objects.
</p>
<p>For example, suppose a user names the object Fit, as in the
<code>LaplacesDemon</code> example. Now, rather than overwriting
object Fit, object Fit is renamed, after updating a million
iterations, to Fit1. As suggested by <code>Consort</code>, another
million iterations are used, but now to create object Fit2. Further
suppose this user specified <code>Thinning=1000</code> in
<code>LaplacesDemon</code>, meaning that the million iterations are
thinned by 1,000, so only 1,000 iterations are retained in each
object, Fit1 and Fit2. In this case, <code>Combine</code> combines the
information in Fit1 and Fit2, and returns an object the user names
Fit3. Fit3 has only 1,000 iterations, which is the result of appending
the iterations in Fit1 and Fit2, and thinning by 2. If 2,000,000
iterations were updated from the beginning, and were thinned by 2,000,
then the same information exists now in Fit3. The <code>Consort</code>
function can now be applied to Fit3, to see if stationarity is found.
If not, then more objects of class <code>demonoid</code> can be collected and
combined.
</p>


<h3>Value</h3>

<p>This function returns an object of class <code>demonoid</code>. For more
information on an object of class <code>demonoid</code>, see the
<code>LaplacesDemon</code> function.
</p>


<h3>Author(s)</h3>

<p>Statisticat, LLC. <a href="mailto:software@bayesian-inference.com">software@bayesian-inference.com</a></p>


<h3>See Also</h3>

<p><code>caterpillar.plot</code>,
<code>Gelman.Diagnostic</code>,
<code>LaplacesDemon</code>, 
<code>LaplacesDemon.hpc</code>, and
<code>Thin</code>.</p>


</div>