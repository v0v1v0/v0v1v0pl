<div class="container">

<table style="width: 100%;"><tr>
<td>lnt_read</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Read in a LexisNexis file</h2>

<h3>Description</h3>

<p>Read a file from LexisNexis in a supported format and convert it to an object
of class LNToutput. Supported formats are TXT, DOC, RTF and PDF files.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lnt_read(
  x,
  encoding = "UTF-8",
  extract_paragraphs = TRUE,
  convert_date = TRUE,
  start_keyword = "auto",
  end_keyword = "auto",
  length_keyword = "auto",
  author_keyword = "auto",
  exclude_lines = "^LOAD-DATE: |^UPDATE: |^GRAFIK: |^GRAPHIC: |^DATELINE: ",
  recursive = FALSE,
  file_type = c("txt", "rtf", "doc", "pdf", "docx", "zip"),
  remove_cover = TRUE,
  remove_classification = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Name(s) of file(s) or one or multiple directories containing files
from LexisNexis to be converted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>encoding</code></td>
<td>
<p>Encoding to be assumed for input files. Defaults to UTF-8
(the LexisNexis standard value).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>extract_paragraphs</code></td>
<td>
<p>A logical flag indicating if the returned object
will include a third data frame with paragraphs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convert_date</code></td>
<td>
<p>A logical flag indicating if it should be tried to
convert the date of each article into Date format. For non-standard dates
provided by LexisNexis it might be safer to convert dates afterwards (see
lnt_asDate).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_keyword</code></td>
<td>
<p>Is used to indicate the beginning of an article. All
articles should have the same number of Beginnings, ends and lengths (which
indicate the last line of metadata). Use regex expression such as "\d+ of
\d+ DOCUMENTS$" (which would catch e.g., the format "2 of 100 DOCUMENTS")
or "auto" to try all common keywords. Keyword search is case sensitive.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>end_keyword</code></td>
<td>
<p>Is used to indicate the end of an article. Works the same
way as start_keyword. A common regex would be "^LANGUAGE: " which catches
language in all caps at the beginning of the line (usually the last line of
an article).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>length_keyword</code></td>
<td>
<p>Is used to indicate the end of the metadata. Works the
same way as start_keyword and end_keyword. A common regex would be
"^LENGTH: " which catches length in all caps at the beginning of the line
(usually the last line of the metadata).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>author_keyword</code></td>
<td>
<p>A keyword to identify the author(s) in the metadata.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exclude_lines</code></td>
<td>
<p>Lines in which these keywords are found are excluded.
Set to <code>character()</code> if you want to turn off this feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recursive</code></td>
<td>
<p>A logical flag indicating whether subdirectories are
searched for more files.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file_type</code></td>
<td>
<p>File types/extensions to be included in search for files.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_cover</code></td>
<td>
<p>Logical. Should the cover page be removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_classification</code></td>
<td>
<p>Logical. Should the classification provided by 
LexisNexis be removed?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>A logical flag indicating whether information should be
printed to the screen.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments passed on to lnt_asDate.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function can produce an LNToutput S4 object with two or
three data.frame: meta, containing all meta information such as date,
author and headline and articles, containing just the article ID and the
text of the articles. When extract_paragraphs is set to TRUE, the output
contains a third data.frame, similar to articles but with articles split
into paragraphs.
</p>
<p>When left to 'auto', the keywords will use the following defaults, which
should be the standard keywords in all languages used by 'LexisNexis':
</p>
<p>* <code>start_keyword = "\d+ of \d+ DOCUMENTS$| Dokument \d+ von \d+$|
  Document \d+ de \d+$"</code>.
</p>
<p>* <code>end_keyword = "^LANGUAGE: |^SPRACHE: |^LANGUE: "</code>.
</p>


<h3>Value</h3>

<p>An LNToutput S4 object consisting of 3 data.frames for metadata,
articles and paragraphs.
</p>


<h3>Author(s)</h3>

<p>Johannes B. Gruber
</p>


<h3>Examples</h3>

<pre><code class="language-R">LNToutput &lt;- lnt_read(lnt_sample(copy = FALSE))
meta.df &lt;- LNToutput@meta
articles.df &lt;- LNToutput@articles
paragraphs.df &lt;- LNToutput@paragraphs
</code></pre>


</div>