<div class="container">

<table style="width: 100%;"><tr>
<td>ismev</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Loglikelihood adjustment for ismev fits</h2>

<h3>Description</h3>

<p>S3 <code>alogLik</code> method to perform loglikelihood adjustment for fitted
extreme value model objects returned from the functions
<code>gev.fit</code>, <code>gpd.fit</code>,
<code>pp.fit</code> and <code>rlarg.fit</code> in the
<code>ismev</code> package.  If regression modelling is used then
the model will need to be re-fitted, see <code>ismev_refits</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'gev.fit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'pp.fit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)

## S3 method for class 'gpd.fit'
alogLik(
  x,
  cluster = NULL,
  use_vcov = TRUE,
  binom = FALSE,
  k,
  inc_cens = TRUE,
  ...
)

## S3 method for class 'rlarg.fit'
alogLik(x, cluster = NULL, use_vcov = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A fitted model object with certain associated S3 methods.
See <strong>Details</strong>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster</code></td>
<td>
<p>A vector or factor indicating from which cluster the
respective log-likelihood contributions from <code>loglik</code> originate.
The length of <code>cluster</code> must be consistent with the <code>estfun</code>
method to be used in the estimation of the 'meat' <code>V</code> of the sandwich
estimator of the covariance matrix of the parameters to be passed to
<code>adjust_loglik</code>.  In most cases, <code>cluster</code>
must have length equal to the number of observations in data.  The
exception is the GP (only) model (<code>binom = FALSE</code>), where the
<code>cluster</code> may either contain a value for each observation in the raw
data, or for each threshold exceedance in the data.
</p>
<p>If <code>cluster</code> is not supplied (is <code>NULL</code>) then it is
assumed that each observation forms its own cluster.
See <strong>Details</strong> for further details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_vcov</code></td>
<td>
<p>A logical scalar.  Should we use the <code>vcov</code> S3 method
for <code>x</code> (if this exists) to estimate the Hessian of the independence
loglikelihood to be passed as the argument <code>H</code> to
<code>adjust_loglik</code>?
Otherwise, <code>H</code> is estimated inside
<code>adjust_loglik</code> using
<code>optimHess</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments to be passed to the functions in the
sandwich package <code>meat</code> (if <code>cluster = NULL</code>),
or <code>meatCL</code> (if <code>cluster</code> is not
<code>NULL</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binom</code></td>
<td>
<p>A logical scalar.  This option is only relevant to
<strong>GP models</strong> and is only available in the <strong>stationary</strong>
(no covariates) case. If <code>binom = FALSE</code> then loglikelihood
adjustment is only performed using the GP model. If <code>binom = TRUE</code>
then loglikelihood adjustment is also performed for inferences about the
probability of threshold exceedance, using a Bernoulli model for the
instances of threshold exceedance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>A non-negative integer scalar.  This option is only relevant to
<strong>GP models</strong> and is only available in the <strong>stationary</strong>
(no covariates) case.  If <code>k</code> is supplied then it is passed as the
run parameter <code class="reqn">K</code> to <code>kgaps</code> for making inferences
about the extremal index <code class="reqn">\theta</code> using the <code class="reqn">K</code>-gaps model of
Suveges and Davison (2010).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inc_cens</code></td>
<td>
<p>A logical scalar.  This argument is only relevant if
<code>k</code> is supplied.  Passed to <code>kgaps</code> to indicate
whether or not to include censored inter-exceedance times, relating to
the first and last observations.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>See <code>alogLik</code> for details.
</p>
<p>If regression modelling is used then the ismev functions
<code>gev.fit</code>, <code>gpd.fit</code>,
<code>pp.fit</code> and <code>rlarg.fit</code>
return residuals but <code>alogLik</code> needs the raw data.
The model will need to be re-fitted, using one of the functions in
<code>ismev_refits</code>, and the user will be prompted to do this
by an error message produced by <code>alogLik</code>.
</p>


<h3>Value</h3>

<p>An object inheriting from class <code>"chandwich"</code>.  See
<code>adjust_loglik</code>.
</p>
<p><code>class(x)</code> is a vector of length 5. The first 3 components are
<code>c("lax", "chandwich", "ismev")</code>.
The remaining 2 components depend on the model that was fitted.
The 4th component is:
<code>"gev"</code> if <code>gev.fit</code>
(or <code>gev_refit</code>) was used;
<code>"gpd"</code> if <code>gpd.fit</code>
(or <code>gpd_refit</code>) was used;
<code>"pp"</code> <code>pp.fit</code>
(or <code>pp_refit</code>) was used;
<code>"rlarg"</code> <code>rlarg.fit</code>
(or <code>rlarg_refit</code>) was used.
The 5th component is
<code>"stat"</code> if <code>x$trans = FALSE</code> and
<code>"nonstat"</code> if <code>x$trans = TRUE</code>.
</p>


<h3>References</h3>

<p>Chandler, R. E. and Bate, S. (2007). Inference for clustered
data using the independence loglikelihood. <em>Biometrika</em>,
<strong>94</strong>(1), 167-183. <a href="https://doi.org/10.1093/biomet/asm015">doi:10.1093/biomet/asm015</a>
</p>
<p>Suveges, M. and Davison, A. C. (2010) Model
misspecification in peaks over threshold analysis, <em>The Annals of
Applied Statistics</em>, <strong>4</strong>(1), 203-221.
<a href="https://doi.org/10.1214/09-AOAS292">doi:10.1214/09-AOAS292</a>
</p>
<p>Zeileis (2006) Object-Oriented Computation and Sandwich
Estimators.  <em>Journal of Statistical Software</em>, <strong>16</strong>, 1-16.
<a href="https://doi.org/10.18637/jss.v016.i09">doi:10.18637/jss.v016.i09</a>
</p>


<h3>See Also</h3>

<p><code>alogLik</code>: loglikelihood adjustment for model fits.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># We need the ismev package
got_ismev &lt;- requireNamespace("ismev", quietly = TRUE)

if (got_ismev) {
  library(ismev)

  # GEV model -----

  # An example from the ismev::gev.fit documentation
  gev_fit &lt;- gev.fit(revdbayes::portpirie, show = FALSE)
  adj_gev_fit &lt;- alogLik(gev_fit)
  summary(adj_gev_fit)

  # An example from chapter 6 of Coles (2001)
  data(fremantle)
  xdat &lt;- fremantle[, "SeaLevel"]
  # Set year 1897 to 1 for consistency with page 113 of Coles (2001)
  ydat &lt;- cbind(fremantle[, "Year"] - 1896, fremantle[, "SOI"])
  gev_fit &lt;- gev_refit(xdat, ydat, mul = 1:2, show = FALSE)
  adj_gev_fit &lt;- alogLik(gev_fit)
  summary(adj_gev_fit)

  # An example from Chandler and Bate (2007)
  gev_fit &lt;- gev_refit(ow$temp, ow, mul = 4, sigl = 4, shl = 4,
                       show = FALSE)
  adj_gev_fit &lt;- alogLik(gev_fit, cluster = ow$year)
  summary(adj_gev_fit)
  # Get closer to the values reported in Table 2 of Chandler and Bate (2007)
  gev_fit &lt;- gev_refit(ow$temp, ow, mul = 4, sigl = 4, shl = 4,
                       show = FALSE, method = "BFGS")
  # Call sandwich::meatCL() with cadjust = FALSE
  adj_gev_fit &lt;- alogLik(gev_fit, cluster = ow$year, cadjust = FALSE)
  summary(adj_gev_fit)

  # GP model -----

  # An example from the ismev::gpd.fit documentation
  
  data(rain)
  rain_fit &lt;- gpd.fit(rain, 10, show = FALSE)
  adj_rain_fit &lt;- alogLik(rain_fit)
  summary(adj_rain_fit)
  # Continuing to the regression example on page 119 of Coles (2001)
  ydat &lt;- as.matrix((1:length(rain)) / length(rain))
  reg_rain_fit &lt;- gpd_refit(rain, 30, ydat = ydat, sigl = 1, siglink = exp,
                            show = FALSE)
  adj_reg_rain_fit &lt;- alogLik(reg_rain_fit)
  summary(adj_reg_rain_fit)
  
  # Binomial-GP model -----

  # Use Newlyn seas surges data from the exdex package
  surges &lt;- exdex::newlyn
  u &lt;- quantile(surges, probs = 0.9)
  newlyn_fit &lt;- gpd.fit(surges, u, show = FALSE)
  # Create 5 clusters each corresponding approximately to 1 year of data
  cluster &lt;- rep(1:5, each = 579)[-1]
  adj_newlyn_fit &lt;- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,
                            cadjust = FALSE)
  summary(adj_newlyn_fit)
  summary(attr(adj_newlyn_fit, "pu_aloglik"))

  # Add inference about the extremal index theta, using K = 1
  adj_newlyn_theta &lt;- alogLik(newlyn_fit, cluster = cluster, binom = TRUE,
                              k = 1, cadjust = FALSE)
  summary(attr(adj_newlyn_theta, "theta"))

  # PP model -----

  # An example from the ismev::pp.fit documentation
  data(rain)
  # Start from the mle to save time
  init &lt;- c(40.55755732, 8.99195409, 0.05088103)
  muinit &lt;- init[1]
  siginit &lt;- init[2]
  shinit &lt;- init[3]
  rain_fit &lt;- pp_refit(rain, 10, muinit = muinit, siginit = siginit,
                       shinit = shinit, show = FALSE)
  adj_rain_fit &lt;- alogLik(rain_fit)
  summary(adj_rain_fit)

  # An example from chapter 7 of Coles (2001).
  # Code from demo ismev::wooster.temps
  data(wooster)
  x &lt;- seq(along = wooster)
  usin &lt;- function(x, a, b, d) {
    return(a + b * sin(((x - d) * 2 * pi) / 365.25))
  }
  wu &lt;- usin(x, -30, 25, -75)
  ydat &lt;- cbind(sin(2 * pi * x / 365.25), cos(2 * pi *x / 365.25))
  # Start from the mle to save time
  init &lt;- c(-15.3454188, 9.6001844, 28.5493828, 0.5067104, 0.1023488,
            0.5129783, -0.3504231)
  muinit &lt;- init[1:3]
  siginit &lt;- init[4:6]
  shinit &lt;- init[7]
  wooster.pp &lt;- pp_refit(-wooster, threshold = wu, ydat = ydat, mul = 1:2,
                         sigl = 1:2, siglink = exp, method = "BFGS",
                         muinit = muinit, siginit = siginit, shinit = shinit,
                         show = FALSE)
  adj_pp_fit &lt;- alogLik(wooster.pp)
  summary(adj_pp_fit)

  # r-largest order statistics model -----

  # An example based on the ismev::rlarg.fit() documentation
  vdata &lt;- revdbayes::venice
  rfit &lt;- rlarg.fit(vdata, muinit = 120.54, siginit = 12.78,
                    shinit = -0.1129, show = FALSE)
  adj_rfit &lt;- alogLik(rfit)
  summary(adj_rfit)

  
  # Adapt this example to add a covariate
  set.seed(30102019)
  ydat &lt;- matrix(runif(nrow(vdata)), nrow(vdata), 1)
  rfit2 &lt;- rlarg_refit(vdata, ydat = ydat, mul = 1,
                       muinit = c(120.54, 0), siginit = 12.78,
                       shinit = -0.1129, show = FALSE)
  adj_rfit2 &lt;- alogLik(rfit2)
  summary(adj_rfit2)
  
}
</code></pre>


</div>