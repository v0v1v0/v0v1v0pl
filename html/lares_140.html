<div class="container">

<table style="width: 100%;"><tr>
<td>model_metrics</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model Metrics and Performance</h2>

<h3>Description</h3>

<p>This function lets the user get a confusion matrix and accuracy, and
for for binary classification models: AUC, Precision, Sensitivity, and
Specificity, given the expected (tags) values and predicted values (scores).
</p>


<h3>Usage</h3>

<pre><code class="language-R">model_metrics(
  tag,
  score,
  multis = NA,
  abc = TRUE,
  thresh = 10,
  auto_n = TRUE,
  thresh_cm = 0.5,
  target = "auto",
  type = "test",
  model_name = NA,
  plots = TRUE,
  quiet = FALSE,
  subtitle = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>tag</code></td>
<td>
<p>Vector. Real known label</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>score</code></td>
<td>
<p>Vector. Predicted value or model's result</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>multis</code></td>
<td>
<p>Data.frame. Containing columns with each category score
(only used when more than 2 categories coexist)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>abc</code></td>
<td>
<p>Boolean. Arrange columns and rows alphabetically
when categorical values?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thresh</code></td>
<td>
<p>Integer. Threshold for selecting binary or regression
models: this number is the threshold of unique values we should
have in <code>'tag'</code> (more than: regression; less than: classification)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>auto_n</code></td>
<td>
<p>Add <code>n_</code> before digits when it's categorical and
not numerical, even though seems numerical?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thresh_cm</code></td>
<td>
<p>Numeric. Value to splits the results for the
confusion matrix. Range of values: (0-1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>Value. Which is your target positive value? If
set to <code>'auto'</code>, the target with largest <code>mean(score)</code> will be
selected. Change the value to overwrite. Only used when binary
categorical model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Character. One of: "train", "test".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_name</code></td>
<td>
<p>Character. Model's name for reference.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plots</code></td>
<td>
<p>Boolean. Create plots objects?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quiet</code></td>
<td>
<p>Boolean. Quiet all messages, warnings, recommendations?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subtitle</code></td>
<td>
<p>Character. Subtitle for plots</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List. Multiple performance metrics that vary depending on
the type of model (classification or regression). If <code>plot=TRUE</code>,
multiple plots are also returned.
</p>


<h3>See Also</h3>

<p>Other Machine Learning: 
<code>ROC()</code>,
<code>conf_mat()</code>,
<code>export_results()</code>,
<code>gain_lift()</code>,
<code>h2o_automl()</code>,
<code>h2o_predict_MOJO()</code>,
<code>h2o_selectmodel()</code>,
<code>impute()</code>,
<code>iter_seeds()</code>,
<code>lasso_vars()</code>,
<code>model_preprocess()</code>,
<code>msplit()</code>
</p>
<p>Other Model metrics: 
<code>ROC()</code>,
<code>conf_mat()</code>,
<code>errors()</code>,
<code>gain_lift()</code>,
<code>loglossBinary()</code>
</p>
<p>Other Calculus: 
<code>corr()</code>,
<code>dist2d()</code>,
<code>quants()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(dfr) # Results for AutoML Predictions
lapply(dfr, head)

# Metrics for Binomial Model
met1 &lt;- model_metrics(dfr$class2$tag, dfr$class2$scores,
  model_name = "Titanic Survived Model",
  plots = FALSE
)
print(met1)

# Metrics for Multi-Categorical Model
met2 &lt;- model_metrics(dfr$class3$tag, dfr$class3$score,
  multis = subset(dfr$class3, select = -c(tag, score)),
  model_name = "Titanic Class Model",
  plots = FALSE
)
print(met2)

# Metrics for Regression Model
met3 &lt;- model_metrics(dfr$regr$tag, dfr$regr$score,
  model_name = "Titanic Fare Model",
  plots = FALSE
)
print(met3)
</code></pre>


</div>