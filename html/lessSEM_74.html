<div class="container">

<table style="width: 100%;"><tr>
<td>addCappedL1</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>addCappedL1</h2>

<h3>Description</h3>

<p>Implements cappedL1 regularization for structural equation models.
The penalty function is given by:
</p>
<p style="text-align: center;"><code class="reqn">p( x_j) = \lambda \min(| x_j|, \theta)</code>
</p>

<p>where <code class="reqn">\theta &gt; 0</code>. The cappedL1 penalty is identical to the lasso for
parameters which are below <code class="reqn">\theta</code> and identical to a constant for parameters
above <code class="reqn">\theta</code>. As adding a constant to the fitting function will not change its
minimum, larger parameters can stay unregularized while smaller ones are set to zero.
</p>


<h3>Usage</h3>

<pre><code class="language-R">addCappedL1(mixedPenalty, regularized, lambdas, thetas)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mixedPenalty</code></td>
<td>
<p>model of class mixedPenalty created with the mixedPenalty function (see ?mixedPenalty)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regularized</code></td>
<td>
<p>vector with names of parameters which are to be regularized.
If you are unsure what these parameters are called, use
getLavaanParameters(model) with your lavaan model object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambdas</code></td>
<td>
<p>numeric vector: values for the tuning parameter lambda</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thetas</code></td>
<td>
<p>parameters whose absolute value is above this threshold will be penalized with
a constant (theta)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Identical to <span class="pkg">regsem</span>, models are specified using <span class="pkg">lavaan</span>. Currently,
most standard SEM are supported. <span class="pkg">lessSEM</span> also provides full information
maximum likelihood for missing data. To use this functionality,
fit your <span class="pkg">lavaan</span> model with the argument <code>sem(..., missing = 'ml')</code>.
<span class="pkg">lessSEM</span> will then automatically switch to full information maximum likelihood
as well.
</p>
<p>CappedL1 regularization:
</p>

<ul><li>
<p> Zhang, T. (2010). Analysis of Multi-stage Convex Relaxation for Sparse Regularization.
Journal of Machine Learning Research, 11, 1081–1107.
</p>
</li></ul>
<p>Regularized SEM
</p>

<ul>
<li>
<p> Huang, P.-H., Chen, H., &amp; Weng, L.-J. (2017). A Penalized Likelihood Method for Structural Equation Modeling. Psychometrika, 82(2), 329–354. https://doi.org/10.1007/s11336-017-9566-9
</p>
</li>
<li>
<p> Jacobucci, R., Grimm, K. J., &amp; McArdle, J. J. (2016). Regularized Structural Equation Modeling. Structural
Equation Modeling: A Multidisciplinary Journal, 23(4), 555–566. https://doi.org/10.1080/10705511.2016.1154793
</p>
</li>
</ul>
<p>For more details on ISTA, see:
</p>

<ul>
<li>
<p> Beck, A., &amp; Teboulle, M. (2009). A Fast Iterative Shrinkage-Thresholding
Algorithm for Linear Inverse Problems. SIAM Journal on Imaging Sciences, 2(1),
183–202. https://doi.org/10.1137/080716542
</p>
</li>
<li>
<p> Gong, P., Zhang, C., Lu, Z., Huang, J., &amp; Ye, J. (2013).
A General Iterative Shrinkage and Thresholding Algorithm for Non-convex
Regularized Optimization Problems. Proceedings of the 30th International
Conference on Machine Learning, 28(2)(2), 37–45.
</p>
</li>
<li>
<p> Parikh, N., &amp; Boyd, S. (2013). Proximal Algorithms. Foundations and
Trends in Optimization, 1(3), 123–231.
</p>
</li>
</ul>
<h3>Value</h3>

<p>Model of class mixedPenalty. Use the fit() - function to fit the model
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(lessSEM)

# Identical to regsem, lessSEM builds on the lavaan
# package for model specification. The first step
# therefore is to implement the model in lavaan.

dataset &lt;- simulateExampleData()

lavaanSyntax &lt;- "
f =~ l1*y1 + l2*y2 + l3*y3 + l4*y4 + l5*y5 + 
     l6*y6 + l7*y7 + l8*y8 + l9*y9 + l10*y10 + 
     l11*y11 + l12*y12 + l13*y13 + l14*y14 + l15*y15
f ~~ 1*f
"

lavaanModel &lt;- lavaan::sem(lavaanSyntax,
                           data = dataset,
                           meanstructure = TRUE,
                           std.lv = TRUE)

# We can add mixed penalties as follows:

regularized &lt;- lavaanModel |&gt;
  # create template for regularized model with mixed penalty:
  mixedPenalty() |&gt;
  # add penalty on loadings l6 - l10:
  addCappedL1(regularized = paste0("l", 11:15), 
          lambdas = seq(0,1,.1),
          thetas = 2.3) |&gt;
  # fit the model:
  fit()
</code></pre>


</div>