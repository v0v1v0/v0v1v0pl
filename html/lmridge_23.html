<div class="container">

<table style="width: 100%;"><tr>
<td>press.lmridge</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Predicted Residual Sum of Squares</h2>

<h3>Description</h3>

<p>The <code>press.lmridge</code> function computes predicted residual sum of squares (PRESS) (see Allen, 1971).</p>


<h3>Usage</h3>

<pre><code class="language-R">press(object, ...)
## S3 method for class 'lmridge'
press(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>An object of class "lmridge".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Not presently used in this implementation.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>All of the <code>n</code> leave-one-out predicted residual sum of squares is calculated by fitting full regression model by using, <code class="reqn">\sum\frac{\hat{e}_{i,k}}{1-\frac{1}{n}-H_{ii_{R,k}}}</code>, where <code class="reqn">H_{ii_{R,k}}</code> is hat matrix from ridge model fit, <code class="reqn">\hat{e_{i,k}}</code> is the ith residual at specific value of <code class="reqn">K</code>.
</p>


<h3>Value</h3>

<p>The <code>press.lmridge</code> produces a vector of PRESS or a matrix of PRESS for scalar or vector values of biasing parameter.
</p>


<h3>Author(s)</h3>

<p>Muhammad Imdad Ullah, Muhammad Aslam</p>


<h3>References</h3>

<p>Allen, D. M. (1971). Mean Square Error of Prediction as a Criterion for Selecting Variables. <em>Technometrics</em>, <strong>13</strong>, 469-475. <a href="https://doi.org/10.1080/00401706.1971.10488811">doi:10.1080/00401706.1971.10488811</a>.
</p>
<p>Allen, D. M. (1974). The Relationship between Variable Selection and Data Augmentation and Method for Prediction. <em>Technometrics</em>, <strong>16</strong>, 125-127. <a href="https://doi.org/10.1080/00401706.1974.10489157">doi:10.1080/00401706.1974.10489157</a>.
</p>
<p>Hoerl, A. E., Kennard, R. W., and Baldwin, K. F. (1975). Ridge Regression: Some Simulation. <em>Communication in Statistics</em>, <strong>4</strong>, 105-123. <a href="https://doi.org/10.1080/03610927508827232">doi:10.1080/03610927508827232</a>.
</p>
<p>Hoerl, A. E. and Kennard, R. W., (1970). Ridge Regression: Biased Estimation of Nonorthogonal Problems. <em>Technometrics</em>, <strong>12</strong>, 55-67. <a href="https://doi.org/10.1080/00401706.1970.10488634">doi:10.1080/00401706.1970.10488634</a>.
</p>
<p>Imdad, M. U. <em>Addressing Linear Regression Models with Correlated Regressors: Some Package Development in R</em> (Doctoral Thesis, Department of Statistics, Bahauddin Zakariya University, Multan, Pakistan), 2017.
</p>


<h3>See Also</h3>

<p>The ridge model fitting <code>lmridge</code>, ridge residual <code>residuals</code>, ridge predicted value <code>predict</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">mod &lt;- lmridge(y~., as.data.frame(Hald), K = seq(0, 0.5, 0.04))
press(mod)
</code></pre>


</div>