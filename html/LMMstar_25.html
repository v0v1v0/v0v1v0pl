<div class="container">

<table style="width: 100%;"><tr>
<td>confint.Wald_lmm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Confidence Intervals for Multivariate Wald Tests</h2>

<h3>Description</h3>

<p>Compute confidence intervals for linear hypothesis tests, possibly with adjustment for multiple comparisons.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'Wald_lmm'
confint(
  object,
  parm,
  level = 0.95,
  method = NULL,
  columns = NULL,
  backtransform = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>a <code>Wald_lmm</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parm</code></td>
<td>
<p>Not used. For compatibility with the generic method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>level</code></td>
<td>
<p>[numeric, 0-1] nominal coverage of the confidence intervals.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>[character] type of adjustment for multiple comparisons, one of <code>"none"</code>, <code>"bonferroni"</code>, ..., <code>"fdr"</code>, <code>"single-step"</code>, <code>"single-step2"</code>.
Alternatively, a method for combining the estimates, one of <code>"average"</code>, <code>"pool.se"</code>, <code>"pool.gls"</code>, <code>"pool.gls1"</code>, <code>"pool.rubin"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>columns</code></td>
<td>
<p>[character vector] Columns to be output.
Can be any of <code>"estimate"</code>, <code>"se"</code>, <code>"statistic"</code>, <code>"df"</code>, <code>"null"</code>, <code>"lower"</code>, <code>"upper"</code>, <code>"p.value"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>backtransform</code></td>
<td>
<p>[logical] should the estimates, standard errors, and confidence intervals be backtransformed?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Not used. For compatibility with the generic method.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><b>Adjustment for multiple comparisons</b>: available methods are:
</p>

<ul>
<li> <p><code>"none"</code>, <code>"bonferroni"</code>, <code>"single-step2"</code>
</p>
</li>
<li> <p><code>"holm"</code>, <code>"hochberg"</code>, <code>"hommel"</code>, <code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>: adjustment performed by [stats::p.adjust()], no confidence interval is computed.
</p>
</li>
<li> <p><code>"single-step"</code>, <code>"free"</code>, <code>"Westfall"</code>, <code>"Shaffer"</code>: adjustment performed by [multcomp::glht()],  for all but the first method no confidence interval is computed.
</p>
</li>
</ul>
<p>Note: method <code>"single-step"</code> adjusts for multiple comparisons using equicoordinate quantiles of the multivariate Student's t-distribution over all tests, instead of the univariate quantiles. It assumes equal degrees of freedom in the marginal and is described in section 7.1 of Dmitrienko et al. (2013) under the name single-step Dunnett procedure. The name <code>"single-step"</code> is borrowed from the multcomp package. In the book Bretz et al. (2010) written by the authors of the package, the procedure is refered to as max-t tests which is the terminology adopted in the LMMstar package.  <br>
When degrees of freedom differs between individual hypotheses, method <code>"single-step2"</code> is recommended. It simulates data using copula whose marginal distributions are Student's t-distribution (with possibly different degrees of freedom) and elliptical copula with parameters the estimated correlation between the test statistics (via the copula package). It then computes the frequency at which the simulated maximum exceed the observed maximum and appropriate quantile of simulated maximum for the confidence interval.
</p>
<p><b>Pooling estimates</b>: available methods are:
</p>

<ul>
<li> <p><code>"average"</code>: average estimates
</p>
</li>
<li> <p><code>"pool.fixse"</code>: weighted average of the estimates, with weights being the inverse of the squared standard error. The uncertainty about the weights is neglected.
</p>
</li>
<li> <p><code>"pool.se"</code>: weighted average of the estimates, with weights being the inverse of the squared standard error. The uncertainty about the weights is computed under independence of the variance parameters between models. 
</p>
</li>
<li> <p><code>"pool.gls"</code>: weighted average of the estimates, with weights being based on the variance-covariance matrix of the estimates. When this matrix is singular, its spectral decomposition is truncated when the correspodning eigenvalues are below <code class="reqn">10^{-12}</code>. The uncertainty about the weights is neglected. 
</p>
</li>
<li> <p><code>"pool.gls1"</code>: similar to <code>"pool.gls"</code> but ensure that the weights are at most 1 in absolute value by shrinking toward the average.
</p>
</li>
<li> <p><code>"pool.rubin"</code>: average of the estimates and compute the uncertainty according to Rubin's rule (Barnard et al. 1999).
</p>
</li>
</ul>
<h3>References</h3>

<p>Barnard and Rubin, <b>Small-sample degrees of freedom with multiple imputation</b>. <em>Biometrika</em> (1999), 86(4):948-955. <br>
Dmitrienko, A. and D'Agostino, R., Sr (2013), <b>Traditional multiplicity adjustment methods in clinical trials</b>. <em>Statist. Med.</em>, 32: 5172-5218.
Frank Bretz, Torsten Hothorn and Peter Westfall (2010), <b>Multiple Comparisons Using R</b>, <em>CRC Press</em>, Boca Raton.
</p>


</div>