<div class="container">

<table style="width: 100%;"><tr>
<td>logisticSVD</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Logistic Singular Value Decomposition</h2>

<h3>Description</h3>

<p>Dimensionality reduction for binary data by extending SVD to 
minimize binomial deviance.
</p>


<h3>Usage</h3>

<pre><code class="language-R">logisticSVD(x, k = 2, quiet = TRUE, max_iters = 1000,
  conv_criteria = 1e-05, random_start = FALSE, start_A, start_B, start_mu,
  partial_decomp = TRUE, main_effects = TRUE, use_irlba)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>matrix with all binary entries</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>rank of the SVD</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quiet</code></td>
<td>
<p>logical; whether the calculation should give feedback</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iters</code></td>
<td>
<p>number of maximum iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conv_criteria</code></td>
<td>
<p>convergence criteria. The difference between average deviance
in successive iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random_start</code></td>
<td>
<p>logical; whether to randomly inititalize the parameters. If <code>FALSE</code>,
algorithm will use an SVD as starting value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_A</code></td>
<td>
<p>starting value for the left singular vectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_B</code></td>
<td>
<p>starting value for the right singular vectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_mu</code></td>
<td>
<p>starting value for mu. Only used if <code>main_effects = TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partial_decomp</code></td>
<td>
<p>logical; if <code>TRUE</code>, the function uses the rARPACK package
to more quickly calculate the SVD. When the number of columns is small, 
the approximation may be less accurate and slower</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main_effects</code></td>
<td>
<p>logical; whether to include main effects in the model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_irlba</code></td>
<td>
<p>depricated. Use <code>partial_decomp</code> instead</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An S3 object of class <code>lsvd</code> which is a list with the
following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>the main effects</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>a <code>k</code>-dimentional orthogonal matrix with the scaled left singular vectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>a <code>k</code>-dimentional orthonormal matrix with the right singular vectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iters</code></td>
<td>
<p>number of iterations required for convergence</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loss_trace</code></td>
<td>
<p>the trace of the average negative log likelihood of the algorithm. 
Should be non-increasing</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prop_deviance_expl</code></td>
<td>
<p>the proportion of deviance explained by this model.
If <code>main_effects = TRUE</code>, the null model is just the main effects, otherwise 
the null model estimates 0 for all natural parameters.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>de Leeuw, Jan, 2006. Principal component analysis of binary data 
by iterated singular value decomposition. Computational Statistics &amp; Data Analysis 
50 (1), 21–39.
</p>
<p>Collins, M., Dasgupta, S., &amp; Schapire, R. E., 2001. A generalization of principal 
components analysis to the exponential family. In NIPS, 617–624.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># construct a low rank matrix in the logit scale
rows = 100
cols = 10
set.seed(1)
mat_logit = outer(rnorm(rows), rnorm(cols))

# generate a binary matrix
mat = (matrix(runif(rows * cols), rows, cols) &lt;= inv.logit.mat(mat_logit)) * 1.0

# run logistic SVD on it
lsvd = logisticSVD(mat, k = 1, main_effects = FALSE, partial_decomp = FALSE)

# Logistic SVD likely does a better job finding latent features
# than standard SVD
plot(svd(mat_logit)$u[, 1], lsvd$A[, 1])
plot(svd(mat_logit)$u[, 1], svd(mat)$u[, 1])
</code></pre>


</div>