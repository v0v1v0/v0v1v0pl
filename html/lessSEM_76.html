<div class="container">

<table style="width: 100%;"><tr>
<td>addLasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>addLasso</h2>

<h3>Description</h3>

<p>Implements lasso regularization for structural equation models.
The penalty function is given by:
</p>
<p style="text-align: center;"><code class="reqn">p( x_j) = \lambda |x_j|</code>
</p>

<p>Lasso regularization will set parameters to zero if <code class="reqn">\lambda</code> is large enough
</p>


<h3>Usage</h3>

<pre><code class="language-R">addLasso(mixedPenalty, regularized, weights = 1, lambdas)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mixedPenalty</code></td>
<td>
<p>model of class mixedPenalty created with the mixedPenalty function (see ?mixedPenalty)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regularized</code></td>
<td>
<p>vector with names of parameters which are to be regularized.
If you are unsure what these parameters are called, use
getLavaanParameters(model) with your lavaan model object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>can be used to give different weights to the different parameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambdas</code></td>
<td>
<p>numeric vector: values for the tuning parameter lambda</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Identical to <span class="pkg">regsem</span>, models are specified using <span class="pkg">lavaan</span>. Currently,
most standard SEM are supported. <span class="pkg">lessSEM</span> also provides full information
maximum likelihood for missing data. To use this functionality,
fit your <span class="pkg">lavaan</span> model with the argument <code>sem(..., missing = 'ml')</code>.
<span class="pkg">lessSEM</span> will then automatically switch to full information maximum likelihood
as well.
</p>
<p>Lasso regularization:
</p>

<ul><li>
<p> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical
Society. Series B (Methodological), 58(1), 267–288.
</p>
</li></ul>
<p>Regularized SEM
</p>

<ul>
<li>
<p> Huang, P.-H., Chen, H., &amp; Weng, L.-J. (2017). A Penalized Likelihood Method for Structural Equation Modeling. Psychometrika, 82(2), 329–354. https://doi.org/10.1007/s11336-017-9566-9
</p>
</li>
<li>
<p> Jacobucci, R., Grimm, K. J., &amp; McArdle, J. J. (2016). Regularized Structural Equation Modeling. Structural
Equation Modeling: A Multidisciplinary Journal, 23(4), 555–566. https://doi.org/10.1080/10705511.2016.1154793
</p>
</li>
</ul>
<p>For more details on GLMNET, see:
</p>

<ul>
<li>
<p> Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010).
Regularization Paths for Generalized Linear Models via Coordinate Descent.
Journal of Statistical Software, 33(1), 1–20. https://doi.org/10.18637/jss.v033.i01
</p>
</li>
<li>
<p> Yuan, G.-X., Chang, K.-W., Hsieh, C.-J., &amp; Lin, C.-J. (2010).
A Comparison of Optimization Methods and Software for Large-scale
L1-regularized Linear Classification. Journal of Machine Learning Research, 11, 3183–3234.
</p>
</li>
<li>
<p> Yuan, G.-X., Ho, C.-H., &amp; Lin, C.-J. (2012).
An improved GLMNET for l1-regularized logistic regression.
The Journal of Machine Learning Research, 13, 1999–2030. https://doi.org/10.1145/2020408.2020421
</p>
</li>
</ul>
<p>For more details on ISTA, see:
</p>

<ul>
<li>
<p> Beck, A., &amp; Teboulle, M. (2009). A Fast Iterative Shrinkage-Thresholding
Algorithm for Linear Inverse Problems. SIAM Journal on Imaging Sciences, 2(1),
183–202. https://doi.org/10.1137/080716542
</p>
</li>
<li>
<p> Gong, P., Zhang, C., Lu, Z., Huang, J., &amp; Ye, J. (2013).
A General Iterative Shrinkage and Thresholding Algorithm for Non-convex
Regularized Optimization Problems. Proceedings of the 30th International
Conference on Machine Learning, 28(2)(2), 37–45.
</p>
</li>
<li>
<p> Parikh, N., &amp; Boyd, S. (2013). Proximal Algorithms. Foundations and
Trends in Optimization, 1(3), 123–231.
</p>
</li>
</ul>
<h3>Value</h3>

<p>Model of class mixedPenalty. Use the fit() - function to fit the model
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(lessSEM)

# Identical to regsem, lessSEM builds on the lavaan
# package for model specification. The first step
# therefore is to implement the model in lavaan.

dataset &lt;- simulateExampleData()

lavaanSyntax &lt;- "
f =~ l1*y1 + l2*y2 + l3*y3 + l4*y4 + l5*y5 + 
     l6*y6 + l7*y7 + l8*y8 + l9*y9 + l10*y10 + 
     l11*y11 + l12*y12 + l13*y13 + l14*y14 + l15*y15
f ~~ 1*f
"

lavaanModel &lt;- lavaan::sem(lavaanSyntax,
                           data = dataset,
                           meanstructure = TRUE,
                           std.lv = TRUE)

# We can add mixed penalties as follows:

regularized &lt;- lavaanModel |&gt;
  # create template for regularized model with mixed penalty:
  mixedPenalty() |&gt;
  # add penalty on loadings l6 - l10:
  addLasso(regularized = paste0("l", 11:15), 
          lambdas = seq(0,1,.1)) |&gt;
  # fit the model:
  fit()
</code></pre>


</div>