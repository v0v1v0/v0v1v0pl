<div class="container">

<table style="width: 100%;"><tr>
<td>VariableImportancePlot</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Barplot comparing the feature importance across different learning methods.</h2>

<h3>Description</h3>

<p>Barplot comparing the feature importance across different learning methods.
</p>


<h3>Usage</h3>

<pre><code class="language-R">VariableImportancePlot(DT = NULL, RF = NULL, GBM = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>DT</code></td>
<td>
<p>A fitted decision tree model object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>RF</code></td>
<td>
<p>A fitted random forest model object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>GBM</code></td>
<td>
<p>A fitted gradient boosting model object</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>This function returns a barplot that compares the standardized feature importance across different tree-based machine learning methods. These measures are computed via the caret package.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(gbm)
colnames(training)[14] &lt;- "perf"
ensemblist &lt;- TreeModels(traindata = training,
methodlist = c("dt", "rf","gbm"),checkprogress = TRUE)

VariableImportancePlot(DT = ensemblist$ModelObject$rpart,
RF = ensemblist$ModelObject$ranger,GBM = ensemblist$ModelObject$gbm)

VariableImportancePlot(RF = ensemblist$ModelObject$ranger,
GBM = ensemblist$ModelObject$gbm)

VariableImportancePlot(DT = ensemblist$ModelObject$rpart)

</code></pre>


</div>