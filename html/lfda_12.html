<div class="container">

<table style="width: 100%;"><tr>
<td>self</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Semi-Supervised Local Fisher Discriminant Analysis(SELF) for
Semi-Supervised Dimensionality Reduction</h2>

<h3>Description</h3>

<p>Performs semi-supervised local fisher discriminant analysis (SELF) on the given data.
SELF is a linear semi-supervised dimensionality reduction method smoothly bridges supervised
LFDA and unsupervised principal component analysis, by which a natural regularization effect
can be obtained when only a small number of labeled samples are available.
</p>


<h3>Usage</h3>

<pre><code class="language-R">self(X, Y, beta = 0.5, r, metric = c("orthonormalized", "plain",
  "weighted"), kNN = 5, minObsPerLabel = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>n x d matrix of original samples.
n is the number of samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>length n vector of class labels</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>degree of semi-supervisedness (0 &lt;= beta &lt;= 1; default is 0.5 )
0: totally supervised (discard all unlabeled samples)
1: totally unsupervised (discard all label information)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>dimensionality of reduced space (default: d)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p>type of metric in the embedding space (no default)
'weighted'        — weighted eigenvectors
'orthonormalized' — orthonormalized
'plain'           — raw eigenvectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kNN</code></td>
<td>
<p>parameter used in local scaling method (default: 5)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minObsPerLabel</code></td>
<td>
<p>the minimum number observations required for each different label(default: 5)</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>list of the SELF results:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>T</code></td>
<td>
<p>d x r transformation matrix (Z = x * T)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>n x r matrix of dimensionality reduced samples</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Yuan Tang
</p>


<h3>References</h3>

<p>Sugiyama, Masashi, et al (2010).
Semi-supervised local Fisher discriminant analysis for dimensionality reduction.
<em>Machine learning</em> 78.1-2: 35-61.
</p>
<p>Sugiyama, M (2007).
Dimensionality reduction of multimodal labeled data by
local Fisher discriminant analysis.
<em>Journal of Machine Learning Research</em>, vol.<b>8</b>, 1027–1061.
</p>
<p>Sugiyama, M (2006).
Local Fisher discriminant analysis for supervised dimensionality reduction.
In W. W. Cohen and A. Moore (Eds.), <em>Proceedings of 23rd International
Conference on Machine Learning (ICML2006)</em>, 905–912.
</p>


<h3>See Also</h3>

<p>See <code>lfda</code> for LFDA and  <code>klfda</code> for the kernelized variant of
LFDA (Kernel LFDA).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
x &lt;- iris[, -5]
y &lt;- iris[, 5]
self(x, y, beta = 0.1, r = 3, metric = "plain")
</code></pre>


</div>