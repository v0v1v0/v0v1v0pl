<div class="container">

<table style="width: 100%;"><tr>
<td>compare.richness.fnc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compare Lexical Richness of Two Texts</h2>

<h3>Description</h3>

<p>Comparisons of lexical richness between two texts are carried out on the basis
of the vocabulary size (number of types) and on the basis of the vocabulary
growth rate.  Variances of the number of types and of the number of hapax
legomena required for the tests are estimated with the help of LNRE models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">compare.richness.fnc(text1, text2, digits = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>text1</code></td>
<td>
<p>First text in the comparison.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>text2</code></td>
<td>
<p>Second text in the comparison.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>Number of decimal digits required for the growth rate.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The comparison for the vocabulary size is carried out with the test statistic
</p>
<p style="text-align: center;"><code class="reqn">Z = \frac{E[V_1] - E[V_2]}{\sqrt{\sigma(V_1)^2 + \sigma(V_2)^2}}</code>
</p>

<p>and the comparison of the growth rates with the test statistic
</p>
<p style="text-align: center;"><code class="reqn">Z = \frac{\frac{1}{N_1}E[V_1(1)] - \frac{1}{N_2}E[V_2]}{\sqrt{\frac{1}{N_1^2}\sigma(V_1(1))^2 + \frac{1}{N_2^2}\sigma(V_2(1))^2}}</code>
</p>

<p>where <code class="reqn">N</code> denotes the sample size in tokens, <code class="reqn">V</code> the vocabulary size,
and <code class="reqn">V(1)</code> the number of hapax legomena.
</p>


<h3>Value</h3>

<p>A summary listing the Chi-Squared measure of goodness of fit for the
LNRE models (available in the zipfR package) used to estimate variances, 
a table listing tokens, types, hapax legomena and the vocabulary growth rate, 
and two-tailed tests for differences in the vocabulary sizes and growth rates with
Z-score and p-value.
</p>


<h3>Note</h3>

<p>It is probably unwise to attempt to apply this function to texts comprising
more than 500,000 words.
</p>


<h3>Author(s)</h3>

<p>R. Harald Baayen 
Radboud University Nijmegen and 
Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands. 
baayen@mpi.nl
</p>


<h3>References</h3>

<p>Baayen, R. H. (2001) <em>Word Frequency Distributions</em>,
Kluwer Academic Publishers, Dordrecht.
</p>


<h3>Examples</h3>

<pre><code class="language-R">	## Not run: 
     data(alice, through, oz)
     compare.richness.fnc(tolower(alice), tolower(through[1:length(alice)]))
     compare.richness.fnc(tolower(alice), tolower(oz[1:25942]))
  
## End(Not run)
</code></pre>


</div>