<div class="container">

<table style="width: 100%;"><tr>
<td>lvglasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Estimate Gaussian Graphical Models with Latent Variables
</h2>

<h3>Description</h3>

<p>Estimate Gaussian graphical models with latent variables using the method in Chandrasekaran et al. (2012).
</p>


<h3>Usage</h3>

<pre><code class="language-R">lvglasso(data, n, p, lambda1, lambda2, rule = "AND")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data set, can be a matrix or data frame with <code class="reqn">n</code> rows and <code class="reqn">p</code> columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>the number of observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>the number of observed variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda1</code></td>
<td>
<p>tuning parameter that encourages estimated graph to be sparse. Lambda1 is proportional to lambda2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda2</code></td>
<td>
<p>tuning parameter that encourages the matrix <code class="reqn">K_{O,H} (K_H)^{-1} K_{H, O}</code> to be low rank, where <code class="reqn">K_H</code> and <code class="reqn">K_{O,H}</code> quantify the dependecies among the latent variables and between the observed variables and latent variables, respectively. The matrix <code class="reqn">K_{O,H} (K_H)^{-1} K_{H, O}</code> summarizes the impact of marginalization over the latent variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rule</code></td>
<td>
<p>rules to combine the inverse covariance matrices. Options are "AND" and "OR". Default is "AND".</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The lvglasso method assumes that all the variables, both observed and latent, are jointly Gaussian, and specifies the conditional distribution of observed variables on the latent variables by a graphical model. Under the high-dimentional setting, this method provides consistent estimators for the conditional graphical model of observed variables conditioned on latent variables. 
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>omega</code></td>
<td>
<p>a matrix that encodes the conditional dependence relationships between sets of two observed variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta</code></td>
<td>
<p>the adjacency matrix with 0 and 1 encoding conditional independence and dependence between sets of two observed variables, respectively</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalties</code></td>
<td>
<p>the penalty values</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Chandrasekaran, V., Parrilo, P. A. &amp; Willsky, A. S. (2012), ‘Latent variable graphical model selection via convex optimization’, Ann. Statist. 40(4), 1935–1967.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#Gaussian distribution with "AND" rule
n &lt;- 50
R &lt;- 20
p &lt;- 30
l &lt;- 2
s &lt;- 2
data &lt;- generate_Gaussian(n, R, p, l, s, sparsityA = 0.95, sparsityobserved = 0.9,
sparsitylatent = 0.2, lwb = 0.3, upb = 0.3, seed = 1)$X

result &lt;- lvglasso(data, n, p, lambda1 = 0.222, lambda2 = 0.1*0.222, rule = "AND")
</code></pre>


</div>