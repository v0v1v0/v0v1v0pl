<div class="container">

<table style="width: 100%;"><tr>
<td>LOCUS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
LOCUS: Low-rank decomposition of brain connectivity matrices with uniform sparsity
</h2>

<h3>Description</h3>

<p>This is the main function in the package. It conducts the LOCUS approach for decomposing brain connectivity data into subnetworks. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">LOCUS(Y, q, V, MaxIteration=100, penalty="SCAD", phi = 0.9, approximation=TRUE, 
preprocess=TRUE, espli1=0.001, espli2=0.001, rho=0.95, silent=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Group-level connectivity data from N subjects, which is of dimension N x p, where p is number of edges. Each row of Y represents a subject's vectorized connectivity matrix by <code>Ltrans</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>Number of ICs/subnetworks to extract.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>Number of nodes in the network. Note: p should be equal to V(V-1)/2. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MaxIteration</code></td>
<td>
<p>Maximum number of iteractions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>The penalization approach for uniform sparsity, which can be <code>NULL</code>, <code>SCAD</code>, and <code>L1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phi</code></td>
<td>
<p><code class="reqn">\phi</code>: tuning parameter for uniform sparse penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approximation</code></td>
<td>
<p>Whether to use an approximated algorithm to speed up the algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>preprocess</code></td>
<td>
<p>Whether to preprocess the data, which reduces the data dimension to <code>q</code> and whiten the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>espli1</code></td>
<td>
<p>Toleration for convergence on mixing coefficient matrix, i.e. A.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>espli2</code></td>
<td>
<p>Toleration for convergence on latent sources, i.e. S.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho</code></td>
<td>
<p><code class="reqn">\rho</code>: tuning parameter for selecting number of ranks in each subnetwork's decomposition.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>silent</code></td>
<td>
<p>Whether to print intermediate steps.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is the main function for LOCUS decomposition of brain connectivity matrices, which is to minimize the following objective function:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^N\|y_i - \sum_{l=1}^q a_{il} s_l\|_2^2 + \phi \sum_{l=1}^q\|s_l\|_*,</code>
</p>

<p>where <code class="reqn">y_i</code> is the transpose of <code class="reqn">i</code>th row in <code class="reqn">Y</code>, <code class="reqn">s_l = L(X_l D_l X_l')</code> represents the <code class="reqn">l</code>th vectorized latent source/subnetwork with low-rank decomposition, <code class="reqn">L</code> is <code>Ltrans</code> function, <code class="reqn">\|\cdot\|_*</code> represents the penalty which can either be NULL, L1, or SCAD (Fan &amp; Li, 2001).
</p>
<p>If user want to do BIC parameter selection of <code class="reqn">\phi, \rho</code> before calling LOCUS main function, one can use <code>LOCUS_BIC_selection</code> to find the best parameter set. Further details can be found in the LOCUS paper.  
</p>


<h3>Value</h3>

<p>An R list from Locus containing the following terms:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Conver</code></td>
<td>
<p>Whether the algorithm is converaged.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>Mixing matrix <code class="reqn">\{a_{il}\}</code> of dimension N by q.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>Subnetworks of dimension q by p, where each row represents a vectorized subnetwork based on <code>Ltrans</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>theta</code></td>
<td>
<p>A list of length q, where <code>theta[[i]]</code> contains the symmetric low-rank decomposition of <code>i</code>th subnetwork. </p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Wang, Y. and Guo, Y. (2023). <em>LOCUS: A novel signal decomposition method for brain network connectivity matrices using low-rank structure with uniform sparsity.</em> Annals of Applied Statistics.
</p>
<p>Fan, J., &amp; Li, R. (2001).  <em>Variable selection via nonconcave penalized likelihood and its oracle properties.</em> Journal of the American statistical Association, 96(456), 1348-1360.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Simulated the data to use. 
V = 50
S1 = S2 = S3 = matrix(0,ncol = V,nrow = V)
S1[5:20,5:20] = 4;S1[23:37,23:37] = 3;S1[40:48,40:48] = 3
S2[15:20,] = -3;S2[,15:20] = -3
S3[15:25,36:45] = 3; S3[36:45,15:25] = 3
Struth = rbind(Ltrans(S1,FALSE) , Ltrans(S2,FALSE), Ltrans(S3,FALSE))
set.seed(100)
Atruth = matrix(rnorm(100*3),nrow=100,ncol=3)
Residual = matrix(rnorm(100*dim(Struth)[2]),nrow=100)
Yraw = Atruth%*%Struth + Residual

##### Run Locus on the data ##### 
Locus_result = LOCUS(Yraw,3,V)

oldpar = par(mfrow=c(2,3))
for(i in 1:dim(Struth)[1]){image(Ltrinv(Struth[i,],V,FALSE))}
for(i in 1:dim(Locus_result$S)[1]){image(Ltrinv(Locus_result$S[i,],V,FALSE))}
par(oldpar)
</code></pre>


</div>