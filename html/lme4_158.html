<div class="container">

<table style="width: 100%;"><tr>
<td>pvalues</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Getting p-values for fitted models</h2>

<h3>Description</h3>

<p>One of the most frequently asked questions about
<code>lme4</code> is "how do I calculate p-values for estimated
parameters?" Previous versions of <code>lme4</code> provided
the <code>mcmcsamp</code> function, which efficiently generated
a Markov chain Monte Carlo sample from the posterior
distribution of the parameters, assuming flat (scaled
likelihood) priors. Due to difficulty in constructing a
version of <code>mcmcsamp</code> that was reliable even in
cases where the estimated random effect variances were
near zero (e.g.
<a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003115.html">https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003115.html</a>),
<code>mcmcsamp</code> has been withdrawn (or more precisely,
not updated to work with <code>lme4</code> versions &gt;=1.0.0).
</p>
<p>Many users, including users of the <code>aovlmer.fnc</code> function from
the <code>languageR</code> package which relies on <code>mcmcsamp</code>, will be
deeply disappointed by this lacuna. Users who need p-values have a
variety of options. In the list below, the methods marked <code>MC</code>
provide explicit model comparisons; <code>CI</code> denotes confidence
intervals; and <code>P</code> denotes parameter-level or sequential tests of
all effects in a model. The starred (*) suggestions provide
finite-size corrections (important when the number of groups is &lt;50);
those marked (+) support GLMMs as well as LMMs.
</p>

<ul>
<li>
<p> likelihood ratio tests via <code>anova</code> or <code>drop1</code> (MC,+) 
</p>
</li>
<li>
<p>profile confidence intervals via <code>profile.merMod</code> and
<code>confint.merMod</code> (CI,+)

</p>
</li>
<li>
<p>parametric bootstrap confidence intervals and model comparisons via
<code>bootMer</code> (or <code>PBmodcomp</code> in the
<code>pbkrtest</code> package) (MC/CI,*,+)

</p>
</li>
<li>
<p>for random effects, simulation tests via the <code>RLRsim</code> package
(MC,*)

</p>
</li>
<li>
<p>for fixed effects, F tests via Kenward-Roger
approximation using <code>KRmodcomp</code> from the
<code>pbkrtest</code> package (MC,*)

</p>
</li>
<li>
<p><code>car::Anova</code> and
<code>lmerTest::anova</code> provide wrappers for
Kenward-Roger-corrected tests using <code>pbkrtest</code>:
<code>lmerTest::anova</code> also provides t tests via the
Satterthwaite approximation (P,*)

</p>
</li>
<li>
<p><code>afex::mixed</code> is another wrapper for
<code>pbkrtest</code> and <code>anova</code> providing
"Type 3" tests of all effects (P,*,+)

</p>
</li>
</ul>
<p><code>arm::sim</code>, or <code>bootMer</code>, can be used
to compute confidence intervals on predictions.
</p>
<p>For <code>glmer</code> models, the <code>summary</code> output provides p-values
based on asymptotic Wald tests (P); while this is standard practice
for generalized linear models, these tests make assumptions both about
the shape of the log-likelihood surface and about the accuracy of
a chi-squared approximation to differences in log-likelihoods.
</p>
<p>When all else fails, don't forget to keep p-values in
perspective:
<a href="https://phdcomics.com/comics/archive.php?comicid=905">https://phdcomics.com/comics/archive.php?comicid=905</a>
</p>


</div>