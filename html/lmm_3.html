<div class="container">

<table style="width: 100%;"><tr>
<td>example</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
lmm package example command file
</h2>

<h3>Description</h3>

<p>The data as contained in <code>marijuana</code> is used to fit
a compound symmetry model with a fixed effect for each occasion and
a random intercept for each subject.
</p>
<p>Since the six measurements per subject were not clearly ordered in
time, instead of a model with time of measurement entered with linear
(or perhaps higher-order polynomial) effects, the model has an
intercept and five dummy codes to allow the population means for the
six occasions to be estimated freely. For a subject i with no missing
values, the covariate matrices will be
</p>
<p>Xi=(
1 1 0 0 0 0, 
1 0 1 0 0 0, 
1 0 0 1 0 0, 
1 0 0 0 1 0, 
1 0 0 0 0 1)
and Zi=(1,1,1,1,1,1)
</p>
<p>The Xi's and Zi's are combined into a single matrix called pred
(Zi is merely the first column of Xi), simply the matrices 
Xi (i=1,...,9), stacked upon each other.
</p>


<h3>See Also</h3>

<p><code>ecmeml</code>, <code>ecmerml</code>,
<code>fastml</code>, <code>fastrml</code>,
<code>fastmcmc</code>, <code>fastmode</code>, 
<code>mgibbs</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">### Model specification ###
data(marijuana)
# To work only on those with complete data
marijuana &lt;- subset(marijuana,!is.na(y))
attach(marijuana)
pred &lt;- cbind(int,dummy1,dummy2,dummy3,dummy4,dummy5)
xcol &lt;- 1:6
zcol &lt;- 1

### ML Estimation ###
ecmeml.result &lt;- ecmeml(y,subj,pred,xcol,zcol)
fastml.result &lt;- fastml(y,subj,pred,xcol,zcol)
#
# which converged in 212 and 8 cycles, respectively. For example, the
# first elemenent of the ML estimate of the fixed effects (the intercept)
# estimates the mean for the last occasion and the other elements of beta
# estimate the differences in means between the first five occasions and
# the last one. So we can find the estimated means for the six occasions.
#
beta.hat &lt;- fastml.result$beta
muhat &lt;- c(beta.hat[2]+beta.hat[1], beta.hat[3]+beta.hat[1],
   beta.hat[4]+beta.hat[1], beta.hat[5]+beta.hat[1],
   beta.hat[6]+beta.hat[1], beta.hat[1]) 

### RML estimation ###
ecmerml.result &lt;- ecmerml(y,subj,pred,xcol,zcol)
fastrml.result &lt;- fastrml(y,subj,pred,xcol,zcol)

### Improved variance estimation in Section 4 ### 
b.hat &lt;- as.vector(fastrml.result$b.hat)
se.new &lt;- sqrt(as.vector(fastrml.result$cov.b.new))
se.old &lt;- sqrt(as.vector(fastrml.result$cov.b))
table2 &lt;- cbind(round(b.hat,3),round(cbind(b.hat-2*se.old,b.hat+2*se.old,
      b.hat-2*se.new,b.hat+2*se.new),2),round(100*(se.new-se.old)/se.old))
dimnames(table2) &lt;- list(paste("Subject",format(1:9)),
   c("Est.","Lower.old","Upper.old","Lower.new","Upper.new","Increase (%)"))
print(table2)
#
# which reproduces Table 2 and compares 95% interval estimates
# under the new method to conventional empirical Bayes intervals.

### MCMC in Section 5 ###
prior &lt;- list(a=3*100,b=3,c=3,Dinv=3*5)
gibbs.result &lt;- mgibbs(y,subj,pred,xcol,zcol,prior=prior,seed=1234,iter=5000)
fmcmc.result &lt;- fastmcmc(y,subj,pred,xcol,zcol,prior=prior,seed=2345,iter=5000)
#
# which run 5,000 cycles for each algorithm and generates Figure 1.
#
# library(ts)
par(mfrow=c(2,1))
acf(log(gibbs.result$psi.series[1,1,]),lag.max=10, ylim=0:1)
acf(log(fmcmc.result$psi.series[1,1,]),lag.max=10, ylim=0:1)
detach(marijuana)
</code></pre>


</div>