<div class="container">

<table style="width: 100%;"><tr>
<td>l0ara</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>fit a generalized linear model with l0 penalty</h2>

<h3>Description</h3>

<p>An adaptive ridge algorithm for feature selection with L0 penalty.
</p>


<h3>Usage</h3>

<pre><code class="language-R">l0ara(x, y, family, lam, standardize, maxit, eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Input matrix, of dimension nobs x nvars; each row is an observation vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Response variable. Quantitative for <code>family="gaussian"</code>; positive quantitative for <code>family="gamma"</code> or <code>family="inv.gaussian"</code> ; a factor with two levels for <code>family="logit"</code>; non-negative counts for <code>family="poisson"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>Response type(see above).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam</code></td>
<td>
<p>A user supplied <code>lambda</code> value. If you have a <code>lam</code> sequence, use <code>cv.l0ara</code> first to select optimal tunning and then refit with <code>lam.min</code> . To use AIC, set <code>lam=2</code>; to use BIC, set <code>lam=log(n)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>Logical flag for data normalization. If <code>standardize=TRUE</code>(default), independent variables in the design matrix <code>x</code> will be standardized with mean 0 and standard deviation 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>Maximum number of passes over the data for <code>lambda</code>. Default value is <code>1e3</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Convergence threshold. Default value is <code>1e-4</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The sequence of models indexed by the parameter lambda is fit using adptive ridge algorithm. The objective function for generalized linear models (including <code>family</code> above) is defined to be </p>
<p style="text-align: center;"><code class="reqn">-(log likelihood)+(\lambda/2)*|\beta|_0</code>
</p>
 <p><code class="reqn">|\beta|_0</code> is the number of non-zero elements in <code class="reqn">\beta</code>. To select the "best" model with AIC or BIC criterion, let <code>lambda</code> to be 2 or <code>log(n)</code>. This adaptive ridge algorithm is developed to approximate L0 penalized generalized linear models with sequential optimization and is efficient for high-dimensional data.
</p>


<h3>Value</h3>

<p>An object with S3 class "l0ara" containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>A vector of coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>Number of nonzero coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>Number of iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The lambda used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Design matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Response variable</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Wenchuan Guo &lt;wguo007@ucr.edu&gt;, Shujie Ma &lt;shujie.ma@ucr.edu&gt;, Zhenqiu Liu &lt;Zhenqiu.Liu@cshs.org&gt;
</p>


<h3>See Also</h3>

<p><code>cv.l0ara</code>, <code>predict.l0ara</code>, <code>coef.l0ara</code>,  <code>plot.l0ara</code> methods.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Linear regression
# Generate design matrix and response variable
n &lt;- 100
p &lt;- 40
x &lt;- matrix(rnorm(n*p), n, p)
beta &lt;- c(1,0,2,3,rep(0,p-4))
noise &lt;- rnorm(n)
y &lt;- x%*%beta+noise
# fit sparse linear regression using BIC 
res.gaussian &lt;- l0ara(x, y, family="gaussian", log(n))

# predict for new observations
print(res.gaussian)
predict(res.gaussian, newx=matrix(rnorm(3,p),3,p))
coef(res.gaussian)

# Logistic regression
# Generate design matrix and response variable
n &lt;- 100
p &lt;- 40
x &lt;- matrix(rnorm(n*p), n, p)
beta &lt;- c(1,0,2,3,rep(0,p-4))
prob &lt;- exp(x%*%beta)/(1+exp(x%*%beta))
y &lt;- rbinom(n, rep(1,n), prob)
# fit sparse logistic regression
res.logit &lt;- l0ara(x, y, family="logit", 0.7)

# predict for new observations
print(res.logit)
predict(res.logit, newx=matrix(rnorm(3,p),3,p))
coef(res.logit)

# Poisson regression
# Generate design matrix and response variable
n &lt;- 100
p &lt;- 40
x &lt;- matrix(rnorm(n*p), n, p)
beta &lt;- c(1,0,0.5,0.3,rep(0,p-4))
mu &lt;- exp(x%*%beta)
y &lt;- rpois(n, mu)
# fit sparse Poisson regression using AIC
res.pois &lt;- l0ara(x, y, family="poisson", 2)

# predict for new observations
print(res.pois)
predict(res.pois, newx=matrix(rnorm(3,p),3,p))
coef(res.pois)
</code></pre>


</div>