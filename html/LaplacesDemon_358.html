<div class="container">

<table style="width: 100%;"><tr>
<td>dist.Horseshoe</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Horseshoe Distribution</h2>

<h3>Description</h3>

<p>This is the density function and random generation from the horseshoe
distribution.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dhs(x, lambda, tau, log=FALSE)
rhs(n, lambda, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>This is the number of draws from the distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>This is a location vector at which to evaluate density.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>This vector is a positive-only local parameter
<code class="reqn">\lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>This scalar is a positive-only global parameter
<code class="reqn">\tau</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log</code></td>
<td>
<p>Logical. If <code>log=TRUE</code>, then the logarithm of the
density is returned.</p>
</td>
</tr>
</table>
<h3>Details</h3>


<ul>
<li>
<p> Application: Multivariate Scale Mixture
</p>
</li>
<li>
<p> Density: (see below)
</p>
</li>
<li>
<p> Inventor: Carvalho et al. (2008)
</p>
</li>
<li>
<p> Notation 1: <code class="reqn">\theta \sim \mathcal{HS}(\lambda,
      \tau)</code>
</p>
</li>
<li>
<p> Notation 2: <code class="reqn">p(\theta) = \mathcal{HS}(\theta | \lambda,
      \tau)</code>
</p>
</li>
<li>
<p> Parameter 1: local scale <code class="reqn">\lambda &gt; 0</code>
</p>
</li>
<li>
<p> Parameter 2: global scale <code class="reqn">\tau &gt; 0</code>
</p>
</li>
<li>
<p> Mean: <code class="reqn">E(\theta)</code>
</p>
</li>
<li>
<p> Variance: <code class="reqn">var(\theta)</code>
</p>
</li>
<li>
<p> Mode: <code class="reqn">mode(\theta)</code>
</p>
</li>
</ul>
<p>The horseshoe distribution (Carvalho et al., 2008) is a heavy-tailed
mixture distribution that can be considered a variance mixture,
and it is in the family of multivariate scale mixtures of normals.
</p>
<p>The horseshoe distribution was proposed as a prior distribution, and
recommended as a default choice for shrinkage priors in the presence of
sparsity. Horseshoe priors are most appropriate in large-p models where
dimension reduction is necessary to avoid overly complex models that
predict poorly, and also perform well in estimating a sparse covariance
matrix via Cholesky decomposition (Carvalho et al., 2009).
</p>
<p>When the number of parameters in variable selection is assumed to be
sparse, meaning that most elements are zero or nearly zero, a horseshoe
prior is a desirable alternative to the Laplace-distributed parameters
in the LASSO, or the parameterization in ridge regression. When the true
value is far from zero, the horseshoe prior leaves the parameter
unshrunk. Yet, the horseshoe prior is accurate in shrinking parameters
that are truly zero or near-zero. Parameters near zero are shrunk more
than parameters far from zero. Therefore, parameters far from zero
experience less shrinkage and are closer to their true values. The
horseshoe prior is valuable in discriminating signal from noise.
</p>
<p>By replacing the Laplace-distributed parameters in LASSO with
horseshoe-distributed parameters and including a global scale, the
result is called horseshoe regression.
</p>


<h3>Value</h3>

<p><code>dhs</code> gives the density and
<code>rhs</code> generates random deviates.
</p>


<h3>References</h3>

<p>Carvalho, C.M., Polson, N.G., and Scott, J.G. (2008). "The Horseshoe
Estimator for Sparse Signals". <em>Discussion Paper 2008-31</em>. Duke
University Department of Statistical Science.
</p>
<p>Carvalho, C.M., Polson, N.G., and Scott, J.G. (2009). "Handling
Sparsity via the Horseshoe". <em>Journal of Machine Learning
Research</em>, 5, p. 73â€“80.
</p>


<h3>See Also</h3>

<p><code>dlaplace</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(LaplacesDemon)
x &lt;- rnorm(100)
lambda &lt;- rhalfcauchy(100, 5)
tau &lt;- 5
x &lt;- dhs(x, lambda, tau, log=TRUE)
x &lt;- rhs(100, lambda=lambda, tau=tau)
plot(density(x))
</code></pre>


</div>