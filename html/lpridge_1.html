<div class="container">

<table style="width: 100%;"><tr>
<td>lpepa</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Local polynomial regression fitting with Epanechnikov weights</h2>

<h3>Description</h3>

<p>Fast and stable algorithm for nonparametric estimation of regression
functions and their derivatives via <b>l</b>ocal <b>p</b>olynomials with
<b>Epa</b>nechnikov weight function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lpepa(x, y, bandwidth, deriv = 0, n.out = 200, x.out = NULL,
      order = deriv+1, mnew = 100, var = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>vector of design points, not necessarily ordered.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of observations of the same length as <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bandwidth</code></td>
<td>
<p>bandwidth(s) for nonparametric estimation.  Either a
number or a vector of the same length as <code>x.out</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deriv</code></td>
<td>
<p>order of derivative of the regression function to be
estimated; defaults to <code>deriv = 0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.out</code></td>
<td>
<p>number of output design points where the function has to
be estimated.  The default is <code>n.out=200</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.out</code></td>
<td>
<p>vector of output design points where the function has to
be estimated.  The default value is an equidistant grid of <code>n.out</code>
points from min(x) to max(x).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order</code></td>
<td>
<p>integer, order of the polynomial used for local
polynomials.  Must be <code class="reqn">\le 10</code> and defaults to
<code>order = deriv+1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mnew</code></td>
<td>
<p>integer forcing to restart the algorithm after <code>mnew</code>
updating steps.
The default is <code>mnew = 100</code>.  For <code>mnew = 1</code> you get a numerically
“super-stable” algorithm (see reference SBE&amp;G below).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var</code></td>
<td>
<p>logical flag: if <code>TRUE</code>, the variance of the estimator
proportional to the residual variance is computed (see details).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>More details are described in the first reference SBE&amp;G (1994)
below.  In S&amp;G, a bad finite sample behaviour of local polynomials
for random designs was found.
For practical use, we therefore propose local polynomial regression
fitting with ridging, as implemented in the function
<code>lpridge</code>.  In <code>lpepa</code>, several parameters described
in SBE&amp;G are fixed either in the fortran
routine or in the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>-function.  There, you find comments how to change them.
</p>

<p>For <code>var=TRUE</code>, the variance of the estimator proportional to the
residual variance is computed, i.e., the exact finite sample variance of the
regression estimator is <code>var(est) = est.var * sigma^2</code>.
</p>


<h3>Value</h3>

<p>a list including used parameters and estimator.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>vector of ordered design points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector of observations ordered according to x.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bandwidth</code></td>
<td>
<p>vector of bandwidths actually used for nonparametric
estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deriv</code></td>
<td>
<p>order of derivative of the regression function estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.out</code></td>
<td>
<p>vector of ordered output design points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>order</code></td>
<td>
<p>order of the polynomial used for local polynomials.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mnew</code></td>
<td>
<p>force to restart the algorithm after mnew updating steps.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var</code></td>
<td>
<p>logical flag: whether the variance of the estimator was computed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>est</code></td>
<td>
<p>estimator of the derivative of order deriv of the
regression function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>est.var</code></td>
<td>
<p>estimator of the variance of est (proportional to
residual variance).</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Originally available from <a href="https://www.ebpi.uzh.ch/">
Biostats, University of Zurich</a> under ‘<span class="file">Manuscripts</span>’, but no longer.


</p>
<p>- Numerical stability and computational speed:
<br>
B. Seifert, M. Brockmann, J. Engel and T. Gasser (1994)
Fast algorithms for nonparametric curve estimation.
<em>J. Computational and Graphical Statistics</em> <b>3</b>, 192–213.
</p>
<p>- Statistical properties:
<br>
Seifert, B. and Gasser, T. (1996)
Finite sample variance of local polynomials: Analysis and solutions.
<em>J. American Statistical Association</em> <b>91</b>(433), 267–275.
</p>
<p>Seifert, B. and Gasser, T. (2000)
Data adaptive ridging in local polynomial
regression.  <em>J. Computational and Graphical Statistics</em> <b>9</b>,
338–360.
</p>
<p>Seifert, B. and Gasser, T. (1998)
Ridging Methods in Local Polynomial Regression.
in: S. Weisberg (ed), <em>Dimension Reduction, Computational Complexity,
and Information</em>, Vol.<b>30</b> of Computing Science &amp; Statistics,
Interface Foundation of North America, 467–476.
</p>
<p>Seifert, B. and Gasser, T. (1998)
Local polynomial smoothing.
in: <em>Encyclopedia of Statistical Sciences</em>,
Update Vol.<b>2</b>, Wiley, 367–372.
</p>
<p>Seifert, B., and Gasser, T. (1996)
Variance properties of local polynomials and ensuing
modifications. in: <em>Statistical Theory and Computational Aspects
of Smoothing</em>, W. Härdle, M. G. Schimek (eds), Physica, 50–127.
</p>


<h3>See Also</h3>

<p><code>lpridge</code>, and also <code>lowess</code> and
<code>loess</code> which do local linear and quadratic regression
quite a bit differently.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(cars)
attach(cars)

epa.sd &lt;- lpepa(speed,dist, bandw=5)		# local polynomials

plot(speed, dist, main = "data(cars) &amp; lp epanechnikov regression")
lines(epa.sd$x.out, epa.sd$est,  col="red")
lines(lowess(speed,dist, f= .5), col="orange")
detach()
</code></pre>


</div>