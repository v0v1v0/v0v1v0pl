<div class="container">

<table style="width: 100%;"><tr>
<td>loo_subsample</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Efficient approximate leave-one-out cross-validation (LOO) using subsampling,
so that less costly and more approximate computation is made for all LOO-fold,
and more costly and accurate computations are made only for m&lt;N LOO-folds.</h2>

<h3>Description</h3>

<p>Efficient approximate leave-one-out cross-validation (LOO) using subsampling,
so that less costly and more approximate computation is made for all LOO-fold,
and more costly and accurate computations are made only for m&lt;N LOO-folds.
</p>


<h3>Usage</h3>

<pre><code class="language-R">loo_subsample(x, ...)

## S3 method for class ''function''
loo_subsample(
  x,
  ...,
  data = NULL,
  draws = NULL,
  observations = 400,
  log_p = NULL,
  log_g = NULL,
  r_eff = 1,
  save_psis = FALSE,
  cores = getOption("mc.cores", 1),
  loo_approximation = "plpd",
  loo_approximation_draws = NULL,
  estimator = "diff_srs",
  llgrad = NULL,
  llhess = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A function. The <strong>Methods (by class)</strong> section, below, has detailed
descriptions of how to specify the inputs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data, draws, ...</code></td>
<td>
<p>For <code>loo_subsample.function()</code>, these are the data,
posterior draws, and other arguments to pass to the log-likelihood
function. Note that for some <code>loo_approximation</code>s, the draws will be replaced
by the posteriors summary statistics to compute loo approximations. See
argument <code>loo_approximation</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observations</code></td>
<td>
<p>The subsample observations to use. The argument can take
four (4) types of arguments:
</p>

<ul>
<li> <p><code>NULL</code> to use all observations. The algorithm then just uses
standard <code>loo()</code> or <code>loo_approximate_posterior()</code>.
</p>
</li>
<li>
<p> A single integer to specify the number of observations to be subsampled.
</p>
</li>
<li>
<p> A vector of integers to provide the indices used to subset the data.
<em>These observations need to be subsampled with the same scheme as given by
the <code>estimator</code> argument</em>.
</p>
</li>
<li>
<p> A <code>psis_loo_ss</code> object to use the same observations that were used in a
previous call to <code>loo_subsample()</code>.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log_p, log_g</code></td>
<td>
<p>Should be supplied only if approximate posterior draws are
used. The default (<code>NULL</code>) indicates draws are from "true" posterior (i.e.
using MCMC). If not <code>NULL</code> then they should be specified as described in
<code>loo_approximate_posterior()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r_eff</code></td>
<td>
<p>Vector of relative effective sample size estimates for the
likelihood (<code>exp(log_lik)</code>) of each observation. This is related to
the relative efficiency of estimating the normalizing term in
self-normalized importance sampling when using posterior draws obtained
with MCMC. If MCMC draws are used and <code>r_eff</code> is not provided then
the reported PSIS effective sample sizes and Monte Carlo error estimates
can be over-optimistic. If the posterior draws are (near) independent then
<code>r_eff=1</code> can be used. <code>r_eff</code> has to be a scalar (same value is used
for all observations) or a vector with length equal to the number of
observations. The default value is 1. See the <code>relative_eff()</code> helper
functions for help computing <code>r_eff</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save_psis</code></td>
<td>
<p>Should the <code>"psis"</code> object created internally by
<code>loo_subsample()</code> be saved in the returned object? See <code>loo()</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cores</code></td>
<td>
<p>The number of cores to use for parallelization. This defaults to
the option <code>mc.cores</code> which can be set for an entire R session by
<code>options(mc.cores = NUMBER)</code>. The old option <code>loo.cores</code> is now
deprecated but will be given precedence over <code>mc.cores</code> until
<code>loo.cores</code> is removed in a future release. <strong>As of version
2.0.0 the default is now 1 core if <code>mc.cores</code> is not set</strong>, but we
recommend using as many (or close to as many) cores as possible.
</p>

<ul><li>
<p> Note for Windows 10 users: it is <strong>strongly</strong>
<a href="https://github.com/stan-dev/loo/issues/94">recommended</a> to avoid using
the <code>.Rprofile</code> file to set <code>mc.cores</code> (using the <code>cores</code> argument or
setting <code>mc.cores</code> interactively or in a script is fine).
</p>
</li></ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loo_approximation</code></td>
<td>
<p>What type of approximation of the loo_i's should be used?
The default is <code>"plpd"</code> (the log predictive density using the posterior expectation).
There are six different methods implemented to approximate loo_i's
(see the references for more details):
</p>

<ul>
<li> <p><code>"plpd"</code>: uses the lpd based on point estimates (i.e., <code class="reqn">p(y_i|\hat{\theta})</code>).
</p>
</li>
<li> <p><code>"lpd"</code>: uses the lpds (i,e., <code class="reqn">p(y_i|y)</code>).
</p>
</li>
<li> <p><code>"tis"</code>: uses truncated importance sampling to approximate PSIS-LOO.
</p>
</li>
<li> <p><code>"waic"</code>: uses waic (i.e., <code class="reqn">p(y_i|y) - p_{waic}</code>).
</p>
</li>
<li> <p><code>"waic_grad_marginal"</code>: uses waic approximation using first order delta
method and posterior marginal variances to approximate <code class="reqn">p_{waic}</code> (ie.
<code class="reqn">p(y_i|\hat{\theta})</code>-p_waic_grad_marginal). Requires gradient of
likelihood function.
</p>
</li>
<li> <p><code>"waic_grad"</code>: uses waic approximation using first order delta method and
posterior covariance to approximate <code class="reqn">p_{waic}</code> (ie.
<code class="reqn">p(y_i|\hat{\theta})</code>-p_waic_grad). Requires gradient of likelihood
function.
</p>
</li>
<li> <p><code>"waic_hess"</code>: uses waic approximation using second order delta method and
posterior covariance to approximate <code class="reqn">p_{waic}</code> (ie.
<code class="reqn">p(y_i|\hat{\theta})</code>-p_waic_grad). Requires gradient and Hessian of
likelihood function.
</p>
</li>
</ul>
<p>As point estimates of <code class="reqn">\hat{\theta}</code>, the posterior expectations
of the parameters are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loo_approximation_draws</code></td>
<td>
<p>The number of posterior draws used when
integrating over the posterior. This is used if <code>loo_approximation</code> is set
to <code>"lpd"</code>, <code>"waic"</code>, or <code>"tis"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimator</code></td>
<td>
<p>How should <code>elpd_loo</code>, <code>p_loo</code> and <code>looic</code> be estimated?
The default is <code>"diff_srs"</code>.
</p>

<ul>
<li> <p><code>"diff_srs"</code>: uses the difference estimator with simple random sampling
without replacement (srs). <code>p_loo</code> is estimated using standard srs.
(Magnusson et al., 2020)
</p>
</li>
<li> <p><code>"hh"</code>: uses the Hansen-Hurwitz estimator with sampling with replacement
proportional to size, where <code>abs</code> of loo_approximation is used as size.
(Magnusson et al., 2019)
</p>
</li>
<li> <p><code>"srs"</code>: uses simple random sampling and ordinary estimation.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>llgrad</code></td>
<td>
<p>The gradient of the log-likelihood. This
is only used when <code>loo_approximation</code> is <code>"waic_grad"</code>,
<code>"waic_grad_marginal"</code>, or <code>"waic_hess"</code>. The default is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>llhess</code></td>
<td>
<p>The Hessian of the log-likelihood. This is only used
with <code>loo_approximation = "waic_hess"</code>. The default is <code>NULL</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <code>loo_subsample()</code> function is an S3 generic and a methods is
currently provided for log-likelihood functions. The implementation works
for both MCMC and for posterior approximations where it is possible to
compute the log density for the approximation.
</p>


<h3>Value</h3>

<p><code>loo_subsample()</code> returns a named list with class <code>c("psis_loo_ss", "psis_loo", "loo")</code>. This has the same structure as objects returned by
<code>loo()</code> but with the additional slot:
</p>

<ul><li> <p><code>loo_subsampling</code>: A list with two vectors, <code>log_p</code> and <code>log_g</code>, of the
same length containing the posterior density and the approximation density
for the individual draws.
</p>
</li></ul>
<h3>Methods (by class)</h3>


<ul><li> <p><code>loo_subsample(`function`)</code>: A function <code>f()</code> that takes arguments <code>data_i</code> and <code>draws</code> and returns a
vector containing the log-likelihood for a single observation <code>i</code> evaluated
at each posterior draw. The function should be written such that, for each
observation <code>i</code> in <code>1:N</code>, evaluating
</p>
<div class="sourceCode"><pre>f(data_i = data[i,, drop=FALSE], draws = draws)
</pre></div>
<p>results in a vector of length <code>S</code> (size of posterior sample). The
log-likelihood function can also have additional arguments but <code>data_i</code> and
<code>draws</code> are required.
</p>
<p>If using the function method then the arguments <code>data</code> and <code>draws</code> must also
be specified in the call to <code>loo()</code>:
</p>

<ul>
<li> <p><code>data</code>: A data frame or matrix containing the data (e.g.
observed outcome and predictors) needed to compute the pointwise
log-likelihood. For each observation <code>i</code>, the <code>i</code>th row of
<code>data</code> will be passed to the <code>data_i</code> argument of the
log-likelihood function.
</p>
</li>
<li> <p><code>draws</code>: An object containing the posterior draws for any
parameters needed to compute the pointwise log-likelihood. Unlike
<code>data</code>, which is indexed by observation, for each observation the
entire object <code>draws</code> will be passed to the <code>draws</code> argument of
the log-likelihood function.
</p>
</li>
<li>
<p> The <code>...</code> can be used if your log-likelihood function takes additional
arguments. These arguments are used like the <code>draws</code> argument in that they
are recycled for each observation.
</p>
</li>
</ul>
</li></ul>
<h3>References</h3>

<p>Magnusson, M., Riis Andersen, M., Jonasson, J. and Vehtari, A. (2019).
Leave-One-Out Cross-Validation for Large Data.
In <em>Thirty-sixth International Conference on Machine Learning</em>,
PMLR 97:4244-4253.
</p>
<p>Magnusson, M., Riis Andersen, M., Jonasson, J. and Vehtari, A. (2020).
Leave-One-Out Cross-Validation for Model Comparison in Large Data.
In <em>Proceedings of the 23rd International Conference on Artificial
Intelligence and Statistics (AISTATS)</em>, PMLR 108:341-351.
</p>


<h3>See Also</h3>

<p><code>loo()</code>, <code>psis()</code>, <code>loo_compare()</code>
</p>


</div>