<div class="container">

<table style="width: 100%;"><tr>
<td>lgb.importance</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute feature importance in a model</h2>

<h3>Description</h3>

<p>Creates a <code>data.table</code> of feature importances in a model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lgb.importance(model, percentage = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>object of class <code>lgb.Booster</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>percentage</code></td>
<td>
<p>whether to show importance in relative percentage.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>For a tree model, a <code>data.table</code> with the following columns:
</p>

<ul>
<li>
<p><code>Feature</code>: Feature names in the model.
</p>
</li>
<li>
<p><code>Gain</code>: The total gain of this feature's splits.
</p>
</li>
<li>
<p><code>Cover</code>: The number of observation related to this feature.
</p>
</li>
<li>
<p><code>Frequency</code>: The number of times a feature splited in trees.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">


data(agaricus.train, package = "lightgbm")
train &lt;- agaricus.train
dtrain &lt;- lgb.Dataset(train$data, label = train$label)

params &lt;- list(
  objective = "binary"
  , learning_rate = 0.1
  , max_depth = -1L
  , min_data_in_leaf = 1L
  , min_sum_hessian_in_leaf = 1.0
  , num_threads = 2L
)
model &lt;- lgb.train(
    params = params
    , data = dtrain
    , nrounds = 5L
)

tree_imp1 &lt;- lgb.importance(model, percentage = TRUE)
tree_imp2 &lt;- lgb.importance(model, percentage = FALSE)

</code></pre>


</div>