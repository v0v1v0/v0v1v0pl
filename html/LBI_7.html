<div class="container">

<table style="width: 100%;"><tr>
<td>LRT</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Likelihood Ratio Test</h2>

<h3>Description</h3>

<p>Likelihood ratio test with given fitting results, sample size, number of parameters, log-likelihoods, and alpha
</p>


<h3>Usage</h3>

<pre><code class="language-R">  LRT(n, pFull, pReduced, logLikFull, logLikReduced, alpha=0.05, Wilks=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>number of observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pFull</code></td>
<td>
<p>number of parameters of full model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pReduced</code></td>
<td>
<p>number of parameters of reduced model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logLikFull</code></td>
<td>
<p>log likelihood of full model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logLikReduced</code></td>
<td>
<p>log likelihood of reduced model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>alpha value for type I error, significance level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Wilks</code></td>
<td>
<p>if TRUE, Wilks theorem (chi-square distribution) will be used, otherwise F distribution will be used.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>It performs likelihood ratio test with given fitting results. The default test is using F distribution. For small n (i.e. less than 100), you need to use F distribution. 
If the residuals are normally distributed, the delta -2 log likelihood (the difference between -2LL, the objective function value of each model) follows exactly an F-distribution, independent of sample size.
When the distribution of the residuals is not normal (no matter what the distribution of the residuals is), it approaches a chi-square distribution as sample size increases (Wilks' theorem).
The extreme distribution of the F-distribution (when the degrees of freedom in the denominator go to infinity) is chi-square distribution.
The p-value from the F-distribution is slightly larger than the p-value from the chi-square distribution, meaning the F-distribution is more conservative. 
The difference decreases as sample size increases.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>number of observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>paraFull</code></td>
<td>
<p>number of parameters of full model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>paraReduced</code></td>
<td>
<p>number of parameters of reduced model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deltaPara</code></td>
<td>
<p>difference of parameter counts</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutoff</code></td>
<td>
<p>cutoff, threshold, critical value of log-likelihood for the test</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deltaLogLik</code></td>
<td>
<p>difference of log likelihood, if negative 0 is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Chisq or Fval</code></td>
<td>
<p>statistics according to the used distribution Chi-square of F</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval</code></td>
<td>
<p>p-value of null hypothesis. i.e. the reduced model is better.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Verdict</code></td>
<td>
<p>the model preferred.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Kyun-Seop Bae k@acr.kr</p>


<h3>References</h3>


<ol>
<li>
<p> Ruppert D, Cressie N, Carroll RJ. A Transformation/Weighting Model For Estimating Michaelis-Menten Parameters. School of Operations Research and Industrial Engineering, College of Engineering, Cornell University. Technical Report No. 796. May 1988.
</p>
</li>
<li>
<p> Scheff√© H. The Analysis of Variance. Wiley. 1959.
</p>
</li>
<li>
<p> Wilks SS. The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses. <em>Annals Math. Statist.</em> 1938;9:60-62
</p>
</li>
</ol>
<h3>Examples</h3>

<pre><code class="language-R">  LRT(20, 4, 2, -58.085, -60.087)
  LRT(20, 4, 2, -58.085, -60.087, Wilks=TRUE)
  LRT(20, 4, 2, -57.315, -66.159)
  LRT(20, 4, 2, -57.315, -66.159, Wilks=TRUE)

  r1 = lm(mpg ~ disp + drat + wt, mtcars)
  r2 = lm(mpg ~ disp + drat, mtcars)
  anova(r2, r1)
  LRT(nrow(mtcars), r1$rank, r2$rank, logLik(r1), logLik(r2))  
</code></pre>


</div>